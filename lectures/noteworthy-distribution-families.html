<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Lecture 8 Noteworthy Distribution Families | DSCI 551: Descriptive Statistics and Probability for Data Science</title>
  <meta name="description" content="Lecture notes for DSCI 551 for the 2019/20 academic year." />
  <meta name="generator" content="bookdown 0.11 and GitBook 2.6.7" />

  <meta property="og:title" content="Lecture 8 Noteworthy Distribution Families | DSCI 551: Descriptive Statistics and Probability for Data Science" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Lecture notes for DSCI 551 for the 2019/20 academic year." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Lecture 8 Noteworthy Distribution Families | DSCI 551: Descriptive Statistics and Probability for Data Science" />
  
  <meta name="twitter:description" content="Lecture notes for DSCI 551 for the 2019/20 academic year." />
  

<meta name="author" content="Vincenzo Coia and Michael Gelbart" />


<meta name="date" content="2019-10-07" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="dependence.html">
<link rel="next" href="linear-algebra-review.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.3/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.9/datatables.js"></script>
<link href="libs/dt-core-1.10.19/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.19/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.19/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">DSCI 551 @ UBC 2019-20</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Lecture Notes</a></li>
<li class="chapter" data-level="1" data-path="depicting-uncertainty.html"><a href="depicting-uncertainty.html"><i class="fa fa-check"></i><b>1</b> Depicting Uncertainty</a><ul>
<li class="chapter" data-level="1.1" data-path="depicting-uncertainty.html"><a href="depicting-uncertainty.html#lecture-learning-objectives"><i class="fa fa-check"></i><b>1.1</b> Lecture Learning Objectives</a></li>
<li class="chapter" data-level="1.2" data-path="depicting-uncertainty.html"><a href="depicting-uncertainty.html#thinking-about-probability"><i class="fa fa-check"></i><b>1.2</b> Thinking about Probability</a><ul>
<li class="chapter" data-level="1.2.1" data-path="depicting-uncertainty.html"><a href="depicting-uncertainty.html#defining-probability-5-min"><i class="fa fa-check"></i><b>1.2.1</b> Defining Probability (5 min)</a></li>
<li class="chapter" data-level="1.2.2" data-path="depicting-uncertainty.html"><a href="depicting-uncertainty.html#calculating-probabilities-using-logic"><i class="fa fa-check"></i><b>1.2.2</b> Calculating Probabilities using Logic</a></li>
<li class="chapter" data-level="1.2.3" data-path="depicting-uncertainty.html"><a href="depicting-uncertainty.html#comparing-probabilities-8-min"><i class="fa fa-check"></i><b>1.2.3</b> Comparing Probabilities (8 min)</a></li>
<li class="chapter" data-level="1.2.4" data-path="depicting-uncertainty.html"><a href="depicting-uncertainty.html#interpreting-probability-5-min"><i class="fa fa-check"></i><b>1.2.4</b> Interpreting Probability (5 min)</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="depicting-uncertainty.html"><a href="depicting-uncertainty.html#probability-distributions"><i class="fa fa-check"></i><b>1.3</b> Probability Distributions</a><ul>
<li class="chapter" data-level="1.3.1" data-path="depicting-uncertainty.html"><a href="depicting-uncertainty.html#examples-of-probability-distributions-3-min"><i class="fa fa-check"></i><b>1.3.1</b> Examples of Probability Distributions (3 min)</a></li>
<li class="chapter" data-level="1.3.2" data-path="depicting-uncertainty.html"><a href="depicting-uncertainty.html#measures-of-central-tendency-and-uncertainty"><i class="fa fa-check"></i><b>1.3.2</b> Measures of central tendency and uncertainty</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="parametric-families.html"><a href="parametric-families.html"><i class="fa fa-check"></i><b>2</b> Parametric families</a><ul>
<li class="chapter" data-level="2.1" data-path="parametric-families.html"><a href="parametric-families.html#learning-objectives"><i class="fa fa-check"></i><b>2.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="2.2" data-path="parametric-families.html"><a href="parametric-families.html#properties-of-distributions-practice"><i class="fa fa-check"></i><b>2.2</b> Properties of Distributions: Practice</a><ul>
<li class="chapter" data-level="2.2.1" data-path="parametric-families.html"><a href="parametric-families.html#demonstration-example-computation-8-min"><i class="fa fa-check"></i><b>2.2.1</b> Demonstration: Example computation (8 min)</a></li>
<li class="chapter" data-level="2.2.2" data-path="parametric-families.html"><a href="parametric-families.html#activity-comparing-variance-to-entropy-12-min"><i class="fa fa-check"></i><b>2.2.2</b> Activity: Comparing Variance to Entropy (12 min)</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="parametric-families.html"><a href="parametric-families.html#expectations-of-transformations"><i class="fa fa-check"></i><b>2.3</b> Expectations of Transformations</a><ul>
<li class="chapter" data-level="2.3.1" data-path="parametric-families.html"><a href="parametric-families.html#linearity-of-expectations-5-min"><i class="fa fa-check"></i><b>2.3.1</b> Linearity of Expectations (5 min)</a></li>
<li class="chapter" data-level="2.3.2" data-path="parametric-families.html"><a href="parametric-families.html#probability-as-an-expectation-3-min"><i class="fa fa-check"></i><b>2.3.2</b> Probability as an Expectation (3 min)</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="parametric-families.html"><a href="parametric-families.html#distribution-families"><i class="fa fa-check"></i><b>2.4</b> Distribution Families</a><ul>
<li class="chapter" data-level="2.4.1" data-path="parametric-families.html"><a href="parametric-families.html#binomial-distribution-8-min"><i class="fa fa-check"></i><b>2.4.1</b> <a href="https://en.wikipedia.org/wiki/Binomial_distribution">Binomial</a> Distribution (8 min)</a></li>
<li class="chapter" data-level="2.4.2" data-path="parametric-families.html"><a href="parametric-families.html#families-vs.distributions-3-min"><i class="fa fa-check"></i><b>2.4.2</b> Families vs. distributions (3 min)</a></li>
<li class="chapter" data-level="2.4.3" data-path="parametric-families.html"><a href="parametric-families.html#parameters-5-min"><i class="fa fa-check"></i><b>2.4.3</b> Parameters (5 min)</a></li>
<li class="chapter" data-level="2.4.4" data-path="parametric-families.html"><a href="parametric-families.html#parameterization-8-min"><i class="fa fa-check"></i><b>2.4.4</b> Parameterization (8 min)</a></li>
<li class="chapter" data-level="2.4.5" data-path="parametric-families.html"><a href="parametric-families.html#distribution-families-in-practice"><i class="fa fa-check"></i><b>2.4.5</b> Distribution Families in Practice</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="parametric-families.html"><a href="parametric-families.html#common-distribution-families-12-min"><i class="fa fa-check"></i><b>2.5</b> Common Distribution Families (12 min)</a><ul>
<li class="chapter" data-level="2.5.1" data-path="parametric-families.html"><a href="parametric-families.html#geometric"><i class="fa fa-check"></i><b>2.5.1</b> <a href="https://en.wikipedia.org/wiki/Geometric_distribution">Geometric</a></a></li>
<li class="chapter" data-level="2.5.2" data-path="parametric-families.html"><a href="parametric-families.html#negative-binomial"><i class="fa fa-check"></i><b>2.5.2</b> <a href="https://en.wikipedia.org/wiki/Negative_binomial_distribution">Negative Binomial</a></a></li>
<li class="chapter" data-level="2.5.3" data-path="parametric-families.html"><a href="parametric-families.html#poisson"><i class="fa fa-check"></i><b>2.5.3</b> <a href="https://en.wikipedia.org/wiki/Poisson_distribution">Poisson</a></a></li>
<li class="chapter" data-level="2.5.4" data-path="parametric-families.html"><a href="parametric-families.html#bernoulli"><i class="fa fa-check"></i><b>2.5.4</b> <a href="https://en.wikipedia.org/wiki/Bernoulli_distribution">Bernoulli</a></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="simulation.html"><a href="simulation.html"><i class="fa fa-check"></i><b>3</b> Simulation</a><ul>
<li class="chapter" data-level="3.1" data-path="simulation.html"><a href="simulation.html#learning-objectives-1"><i class="fa fa-check"></i><b>3.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="3.2" data-path="simulation.html"><a href="simulation.html#review-activity-15-min"><i class="fa fa-check"></i><b>3.2</b> Review Activity (15 min)</a></li>
<li class="chapter" data-level="3.3" data-path="simulation.html"><a href="simulation.html#random-samples-terminology-5-min"><i class="fa fa-check"></i><b>3.3</b> Random Samples: Terminology (5 min)</a></li>
<li class="chapter" data-level="3.4" data-path="simulation.html"><a href="simulation.html#seeds-5-min"><i class="fa fa-check"></i><b>3.4</b> Seeds (5 min)</a></li>
<li class="chapter" data-level="3.5" data-path="simulation.html"><a href="simulation.html#generating-random-samples-code"><i class="fa fa-check"></i><b>3.5</b> Generating Random Samples: Code</a><ul>
<li class="chapter" data-level="3.5.1" data-path="simulation.html"><a href="simulation.html#from-finite-number-of-categories-5-min"><i class="fa fa-check"></i><b>3.5.1</b> From Finite Number of Categories (5 min)</a></li>
<li class="chapter" data-level="3.5.2" data-path="simulation.html"><a href="simulation.html#from-distribution-families-5-min"><i class="fa fa-check"></i><b>3.5.2</b> From Distribution Families (5 min)</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="simulation.html"><a href="simulation.html#running-simulations"><i class="fa fa-check"></i><b>3.6</b> Running Simulations</a><ul>
<li class="chapter" data-level="3.6.1" data-path="simulation.html"><a href="simulation.html#code-for-empirical-quantities-0-min"><i class="fa fa-check"></i><b>3.6.1</b> Code for empirical quantities (0 min)</a></li>
<li class="chapter" data-level="3.6.2" data-path="simulation.html"><a href="simulation.html#basic-simulation-10-min"><i class="fa fa-check"></i><b>3.6.2</b> Basic Simulation (10 min)</a></li>
<li class="chapter" data-level="3.6.3" data-path="simulation.html"><a href="simulation.html#multi-step-simulations-10-min"><i class="fa fa-check"></i><b>3.6.3</b> Multi-Step Simulations (10 min)</a></li>
<li class="chapter" data-level="3.6.4" data-path="simulation.html"><a href="simulation.html#mixture-distributions"><i class="fa fa-check"></i><b>3.6.4</b> Mixture distributions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="joint-probability-part-i.html"><a href="joint-probability-part-i.html"><i class="fa fa-check"></i><b>4</b> Joint Probability, Part I</a><ul>
<li class="chapter" data-level="4.1" data-path="joint-probability-part-i.html"><a href="joint-probability-part-i.html#learning-objectives-2"><i class="fa fa-check"></i><b>4.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="4.2" data-path="joint-probability-part-i.html"><a href="joint-probability-part-i.html#conditional-distributions-15-min"><i class="fa fa-check"></i><b>4.2</b> Conditional Distributions (15 min)</a></li>
<li class="chapter" data-level="4.3" data-path="joint-probability-part-i.html"><a href="joint-probability-part-i.html#joint-distributions-25-min"><i class="fa fa-check"></i><b>4.3</b> Joint Distributions (25 min)</a><ul>
<li class="chapter" data-level="4.3.1" data-path="joint-probability-part-i.html"><a href="joint-probability-part-i.html#example-length-of-stay-vs.gang-demand"><i class="fa fa-check"></i><b>4.3.1</b> Example: Length of Stay vs. Gang Demand</a></li>
<li class="chapter" data-level="4.3.2" data-path="joint-probability-part-i.html"><a href="joint-probability-part-i.html#marginal-distributions"><i class="fa fa-check"></i><b>4.3.2</b> Marginal Distributions</a></li>
<li class="chapter" data-level="4.3.3" data-path="joint-probability-part-i.html"><a href="joint-probability-part-i.html#calculating-marginals-from-the-joint"><i class="fa fa-check"></i><b>4.3.3</b> Calculating Marginals from the Joint</a></li>
<li class="chapter" data-level="4.3.4" data-path="joint-probability-part-i.html"><a href="joint-probability-part-i.html#conditioning-on-one-variable"><i class="fa fa-check"></i><b>4.3.4</b> Conditioning on one Variable</a></li>
<li class="chapter" data-level="4.3.5" data-path="joint-probability-part-i.html"><a href="joint-probability-part-i.html#law-of-total-probabilityexpectation"><i class="fa fa-check"></i><b>4.3.5</b> Law of Total Probability/Expectation</a></li>
<li class="chapter" data-level="4.3.6" data-path="joint-probability-part-i.html"><a href="joint-probability-part-i.html#exercises-10-min"><i class="fa fa-check"></i><b>4.3.6</b> Exercises (10 min)</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="joint-probability-part-i.html"><a href="joint-probability-part-i.html#dependence-concepts"><i class="fa fa-check"></i><b>4.4</b> Dependence concepts</a><ul>
<li class="chapter" data-level="4.4.1" data-path="joint-probability-part-i.html"><a href="joint-probability-part-i.html#independence-5-min"><i class="fa fa-check"></i><b>4.4.1</b> Independence (5 min)</a></li>
<li class="chapter" data-level="4.4.2" data-path="joint-probability-part-i.html"><a href="joint-probability-part-i.html#measures-of-dependence-15-min"><i class="fa fa-check"></i><b>4.4.2</b> Measures of dependence (15 min)</a></li>
<li class="chapter" data-level="4.4.3" data-path="joint-probability-part-i.html"><a href="joint-probability-part-i.html#variance-of-a-sum-2-min"><i class="fa fa-check"></i><b>4.4.3</b> Variance of a sum (2 min)</a></li>
<li class="chapter" data-level="4.4.4" data-path="joint-probability-part-i.html"><a href="joint-probability-part-i.html#dependence-as-separate-from-the-marginals-5-min-optional"><i class="fa fa-check"></i><b>4.4.4</b> Dependence as separate from the marginals (5 min) (Optional)</a></li>
<li class="chapter" data-level="4.4.5" data-path="joint-probability-part-i.html"><a href="joint-probability-part-i.html#dependence-as-giving-us-more-information-5-min-optional"><i class="fa fa-check"></i><b>4.4.5</b> Dependence as giving us more information (5 min) (Optional)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="continuous-distributions.html"><a href="continuous-distributions.html"><i class="fa fa-check"></i><b>5</b> Continuous Distributions</a><ul>
<li class="chapter" data-level="5.1" data-path="continuous-distributions.html"><a href="continuous-distributions.html#roadmap"><i class="fa fa-check"></i><b>5.1</b> Roadmap</a></li>
<li class="chapter" data-level="5.2" data-path="continuous-distributions.html"><a href="continuous-distributions.html#learning-objectives-3"><i class="fa fa-check"></i><b>5.2</b> Learning Objectives</a></li>
<li class="chapter" data-level="5.3" data-path="continuous-distributions.html"><a href="continuous-distributions.html#continuous-random-variables-10-min"><i class="fa fa-check"></i><b>5.3</b> Continuous random variables (10 min)</a></li>
<li class="chapter" data-level="5.4" data-path="continuous-distributions.html"><a href="continuous-distributions.html#density-functions-20-min"><i class="fa fa-check"></i><b>5.4</b> Density Functions (20 min)</a><ul>
<li class="chapter" data-level="5.4.1" data-path="continuous-distributions.html"><a href="continuous-distributions.html#example-low-purity-octane"><i class="fa fa-check"></i><b>5.4.1</b> Example: “Low Purity Octane”</a></li>
<li class="chapter" data-level="5.4.2" data-path="continuous-distributions.html"><a href="continuous-distributions.html#example-monthly-expenses"><i class="fa fa-check"></i><b>5.4.2</b> Example: Monthly Expenses</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="continuous-distributions.html"><a href="continuous-distributions.html#distribution-properties-25-min"><i class="fa fa-check"></i><b>5.5</b> Distribution Properties (25 min)</a><ul>
<li class="chapter" data-level="5.5.1" data-path="continuous-distributions.html"><a href="continuous-distributions.html#mean-variance-mode-and-entropy-again-5-min"><i class="fa fa-check"></i><b>5.5.1</b> Mean, Variance, Mode, and Entropy (again) (5 min)</a></li>
<li class="chapter" data-level="5.5.2" data-path="continuous-distributions.html"><a href="continuous-distributions.html#median-5-min"><i class="fa fa-check"></i><b>5.5.2</b> Median (5 min)</a></li>
<li class="chapter" data-level="5.5.3" data-path="continuous-distributions.html"><a href="continuous-distributions.html#quantiles-5-min"><i class="fa fa-check"></i><b>5.5.3</b> Quantiles (5 min)</a></li>
<li class="chapter" data-level="5.5.4" data-path="continuous-distributions.html"><a href="continuous-distributions.html#prediction-intervals-5-min"><i class="fa fa-check"></i><b>5.5.4</b> Prediction Intervals (5 min)</a></li>
<li class="chapter" data-level="5.5.5" data-path="continuous-distributions.html"><a href="continuous-distributions.html#skewness-5-min"><i class="fa fa-check"></i><b>5.5.5</b> Skewness (5 min)</a></li>
<li class="chapter" data-level="5.5.6" data-path="continuous-distributions.html"><a href="continuous-distributions.html#examples"><i class="fa fa-check"></i><b>5.5.6</b> Examples</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html"><i class="fa fa-check"></i><b>6</b> Joint Probability, Part II</a><ul>
<li class="chapter" data-level="6.1" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html#learning-objectives-4"><i class="fa fa-check"></i><b>6.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="6.2" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html#depicting-distributions-25-min"><i class="fa fa-check"></i><b>6.2</b> Depicting Distributions (25 min)</a><ul>
<li class="chapter" data-level="6.2.1" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html#cumulative-density-functions-cdfs-distribution-functions"><i class="fa fa-check"></i><b>6.2.1</b> Cumulative Density Functions (cdf’s) / Distribution Functions</a></li>
<li class="chapter" data-level="6.2.2" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html#survival-function-2-min"><i class="fa fa-check"></i><b>6.2.2</b> Survival Function (2 min)</a></li>
<li class="chapter" data-level="6.2.3" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html#quantile-function-5-min"><i class="fa fa-check"></i><b>6.2.3</b> Quantile Function (5 min)</a></li>
<li class="chapter" data-level="6.2.4" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html#other-ways-of-depicting-a-distribution-optional-1-min"><i class="fa fa-check"></i><b>6.2.4</b> Other ways of depicting a distribution (Optional) (1 min)</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html#common-distribution-families-continuous-part-i-15-min"><i class="fa fa-check"></i><b>6.3</b> Common Distribution Families: Continuous, Part I (15 min)</a><ul>
<li class="chapter" data-level="6.3.1" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html#uniform-3-min"><i class="fa fa-check"></i><b>6.3.1</b> <a href="https://en.wikipedia.org/wiki/Uniform_distribution_(continuous)">Uniform</a> (3 min)</a></li>
<li class="chapter" data-level="6.3.2" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html#gaussian-normal-4-min"><i class="fa fa-check"></i><b>6.3.2</b> <a href="https://en.wikipedia.org/wiki/Normal_distribution">Gaussian / Normal</a> (4 min)</a></li>
<li class="chapter" data-level="6.3.3" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html#log-normal-family"><i class="fa fa-check"></i><b>6.3.3</b> <a href="https://en.wikipedia.org/wiki/Log-normal_distribution">Log-Normal</a> Family</a></li>
<li class="chapter" data-level="6.3.4" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html#exponential-family"><i class="fa fa-check"></i><b>6.3.4</b> <a href="https://en.wikipedia.org/wiki/Exponential_distribution">Exponential</a> Family</a></li>
<li class="chapter" data-level="6.3.5" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html#weibull-family"><i class="fa fa-check"></i><b>6.3.5</b> <a href="https://en.wikipedia.org/wiki/Weibull_distribution">Weibull</a> Family</a></li>
<li class="chapter" data-level="6.3.6" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html#beta-family"><i class="fa fa-check"></i><b>6.3.6</b> <a href="https://en.wikipedia.org/wiki/Beta_distribution">Beta</a> Family</a></li>
<li class="chapter" data-level="6.3.7" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html#relevant-r-functions-8-min"><i class="fa fa-check"></i><b>6.3.7</b> Relevant R functions (8 min)</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html#multivariate-distributions-continuous-20-min"><i class="fa fa-check"></i><b>6.4</b> Multivariate Distributions: Continuous (20 min)</a><ul>
<li class="chapter" data-level="6.4.1" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html#multivariate-densitiespdfs"><i class="fa fa-check"></i><b>6.4.1</b> Multivariate Densities/pdf’s</a></li>
<li class="chapter" data-level="6.4.2" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html#calculating-probabilities"><i class="fa fa-check"></i><b>6.4.2</b> Calculating Probabilities</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html#conditional-distributions-revisited-15-min"><i class="fa fa-check"></i><b>6.5</b> Conditional Distributions, revisited (15 min)</a><ul>
<li class="chapter" data-level="6.5.1" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html#when-pa-0"><i class="fa fa-check"></i><b>6.5.1</b> When <span class="math inline">\(P(A) = 0\)</span></a></li>
<li class="chapter" data-level="6.5.2" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html#when-pb-0"><i class="fa fa-check"></i><b>6.5.2</b> When <span class="math inline">\(P(B) = 0\)</span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="dependence.html"><a href="dependence.html"><i class="fa fa-check"></i><b>7</b> Dependence</a><ul>
<li class="chapter" data-level="7.1" data-path="dependence.html"><a href="dependence.html#learning-objectives-5"><i class="fa fa-check"></i><b>7.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="7.2" data-path="dependence.html"><a href="dependence.html#drawing-multidimensional-functions-5-min"><i class="fa fa-check"></i><b>7.2</b> Drawing multidimensional functions (5 min)</a><ul>
<li class="chapter" data-level="7.2.1" data-path="dependence.html"><a href="dependence.html#a-possible-point-of-confusion-empirical-contour-plots"><i class="fa fa-check"></i><b>7.2.1</b> A possible point of confusion: empirical contour plots</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="dependence.html"><a href="dependence.html#independence-revisited-10-min"><i class="fa fa-check"></i><b>7.3</b> Independence Revisited (10 min)</a><ul>
<li class="chapter" data-level="7.3.1" data-path="dependence.html"><a href="dependence.html#definition-in-the-continuous-case"><i class="fa fa-check"></i><b>7.3.1</b> Definition in the Continuous Case</a></li>
<li class="chapter" data-level="7.3.2" data-path="dependence.html"><a href="dependence.html#independence-visualized"><i class="fa fa-check"></i><b>7.3.2</b> Independence Visualized</a></li>
<li class="chapter" data-level="7.3.3" data-path="dependence.html"><a href="dependence.html#activity"><i class="fa fa-check"></i><b>7.3.3</b> Activity</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="dependence.html"><a href="dependence.html#harvesting-dependence-20-min"><i class="fa fa-check"></i><b>7.4</b> Harvesting Dependence (20 min)</a><ul>
<li class="chapter" data-level="7.4.1" data-path="dependence.html"><a href="dependence.html#example-river-flow"><i class="fa fa-check"></i><b>7.4.1</b> Example: River Flow</a></li>
<li class="chapter" data-level="7.4.2" data-path="dependence.html"><a href="dependence.html#direction-of-dependence"><i class="fa fa-check"></i><b>7.4.2</b> Direction of Dependence</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="dependence.html"><a href="dependence.html#marginal-distributions-20-min"><i class="fa fa-check"></i><b>7.5</b> Marginal Distributions (20 min)</a><ul>
<li class="chapter" data-level="7.5.1" data-path="dependence.html"><a href="dependence.html#marginal-distribution-from-conditional"><i class="fa fa-check"></i><b>7.5.1</b> Marginal Distribution from Conditional</a></li>
<li class="chapter" data-level="7.5.2" data-path="dependence.html"><a href="dependence.html#marginal-mean-from-conditional"><i class="fa fa-check"></i><b>7.5.2</b> Marginal Mean from Conditional</a></li>
<li class="chapter" data-level="7.5.3" data-path="dependence.html"><a href="dependence.html#marginal-quantiles-from-conditional"><i class="fa fa-check"></i><b>7.5.3</b> Marginal Quantiles from Conditional</a></li>
<li class="chapter" data-level="7.5.4" data-path="dependence.html"><a href="dependence.html#activity-1"><i class="fa fa-check"></i><b>7.5.4</b> Activity</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="dependence.html"><a href="dependence.html#multivariate-gaussiannormal-family-20-min"><i class="fa fa-check"></i><b>7.6</b> Multivariate Gaussian/Normal Family (20 min)</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="noteworthy-distribution-families.html"><a href="noteworthy-distribution-families.html"><i class="fa fa-check"></i><b>8</b> Noteworthy Distribution Families</a><ul>
<li class="chapter" data-level="8.1" data-path="noteworthy-distribution-families.html"><a href="noteworthy-distribution-families.html#learning-objectives-6"><i class="fa fa-check"></i><b>8.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="8.2" data-path="noteworthy-distribution-families.html"><a href="noteworthy-distribution-families.html#more-univariate-distribution-families-5-min"><i class="fa fa-check"></i><b>8.2</b> More Univariate Distribution Families (5 min)</a></li>
<li class="chapter" data-level="8.3" data-path="noteworthy-distribution-families.html"><a href="noteworthy-distribution-families.html#multivariate-gaussiannormal-family-20-min-1"><i class="fa fa-check"></i><b>8.3</b> Multivariate Gaussian/Normal Family (20 min)</a><ul>
<li class="chapter" data-level="8.3.1" data-path="noteworthy-distribution-families.html"><a href="noteworthy-distribution-families.html#parameters"><i class="fa fa-check"></i><b>8.3.1</b> Parameters</a></li>
<li class="chapter" data-level="8.3.2" data-path="noteworthy-distribution-families.html"><a href="noteworthy-distribution-families.html#visualizing-bivariate-gaussian-density"><i class="fa fa-check"></i><b>8.3.2</b> Visualizing Bivariate Gaussian Density</a></li>
<li class="chapter" data-level="8.3.3" data-path="noteworthy-distribution-families.html"><a href="noteworthy-distribution-families.html#properties"><i class="fa fa-check"></i><b>8.3.3</b> Properties</a></li>
<li class="chapter" data-level="8.3.4" data-path="noteworthy-distribution-families.html"><a href="noteworthy-distribution-families.html#activity-2"><i class="fa fa-check"></i><b>8.3.4</b> Activity</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="noteworthy-distribution-families.html"><a href="noteworthy-distribution-families.html#break-and-evaluations-8-min"><i class="fa fa-check"></i><b>8.4</b> Break and Evaluations (8 min)</a></li>
<li class="chapter" data-level="8.5" data-path="noteworthy-distribution-families.html"><a href="noteworthy-distribution-families.html#mixture-distributions-20-min"><i class="fa fa-check"></i><b>8.5</b> Mixture distributions (20 min)</a><ul>
<li class="chapter" data-level="8.5.1" data-path="noteworthy-distribution-families.html"><a href="noteworthy-distribution-families.html#example-mixture-of-gaussians"><i class="fa fa-check"></i><b>8.5.1</b> Example: Mixture of Gaussians</a></li>
<li class="chapter" data-level="8.5.2" data-path="noteworthy-distribution-families.html"><a href="noteworthy-distribution-families.html#application-clustering"><i class="fa fa-check"></i><b>8.5.2</b> Application: Clustering</a></li>
<li class="chapter" data-level="8.5.3" data-path="noteworthy-distribution-families.html"><a href="noteworthy-distribution-families.html#application-zero-inflated-models"><i class="fa fa-check"></i><b>8.5.3</b> Application: Zero-Inflated Models</a></li>
<li class="chapter" data-level="8.5.4" data-path="noteworthy-distribution-families.html"><a href="noteworthy-distribution-families.html#application-bayesian-statistics"><i class="fa fa-check"></i><b>8.5.4</b> Application: Bayesian Statistics</a></li>
<li class="chapter" data-level="8.5.5" data-path="noteworthy-distribution-families.html"><a href="noteworthy-distribution-families.html#activity-3"><i class="fa fa-check"></i><b>8.5.5</b> Activity</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="noteworthy-distribution-families.html"><a href="noteworthy-distribution-families.html#topics-in-the-appendix"><i class="fa fa-check"></i><b>8.6</b> Topics in the Appendix</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix (Optional)</b></span></li>
<li class="chapter" data-level="A" data-path="linear-algebra-review.html"><a href="linear-algebra-review.html"><i class="fa fa-check"></i><b>A</b> Linear Algebra Review</a><ul>
<li class="chapter" data-level="A.1" data-path="linear-algebra-review.html"><a href="linear-algebra-review.html#review-of-vectors-and-linear-algebra"><i class="fa fa-check"></i><b>A.1</b> Review of vectors and linear algebra</a><ul>
<li class="chapter" data-level="A.1.1" data-path="linear-algebra-review.html"><a href="linear-algebra-review.html#vectors"><i class="fa fa-check"></i><b>A.1.1</b> Vectors</a></li>
<li class="chapter" data-level="A.1.2" data-path="linear-algebra-review.html"><a href="linear-algebra-review.html#matrices"><i class="fa fa-check"></i><b>A.1.2</b> Matrices</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="linear-algebra-review.html"><a href="linear-algebra-review.html#random-vectors"><i class="fa fa-check"></i><b>A.2</b> Random vectors</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="bayes-theorem.html"><a href="bayes-theorem.html"><i class="fa fa-check"></i><b>B</b> Bayes’ Theorem</a></li>
<li class="chapter" data-level="C" data-path="heavy-tailed-distributions.html"><a href="heavy-tailed-distributions.html"><i class="fa fa-check"></i><b>C</b> Heavy-Tailed Distributions</a><ul>
<li class="chapter" data-level="C.1" data-path="heavy-tailed-distributions.html"><a href="heavy-tailed-distributions.html#sensitivity-of-the-mean-to-extremes"><i class="fa fa-check"></i><b>C.1</b> Sensitivity of the mean to extremes</a></li>
<li class="chapter" data-level="C.2" data-path="heavy-tailed-distributions.html"><a href="heavy-tailed-distributions.html#heavy-tailed-distributions-1"><i class="fa fa-check"></i><b>C.2</b> Heavy-tailed Distributions</a></li>
<li class="chapter" data-level="C.3" data-path="heavy-tailed-distributions.html"><a href="heavy-tailed-distributions.html#heavy-tailed-distribution-families"><i class="fa fa-check"></i><b>C.3</b> Heavy-tailed distribution families</a></li>
<li class="chapter" data-level="C.4" data-path="heavy-tailed-distributions.html"><a href="heavy-tailed-distributions.html#extreme-value-analysis"><i class="fa fa-check"></i><b>C.4</b> Extreme Value Analysis</a></li>
<li class="chapter" data-level="C.5" data-path="heavy-tailed-distributions.html"><a href="heavy-tailed-distributions.html#multivariate-students-t-distributions"><i class="fa fa-check"></i><b>C.5</b> Multivariate Student’s <em>t</em> distributions</a></li>
</ul></li>
<li class="chapter" data-level="D" data-path="generating-continuous-data.html"><a href="generating-continuous-data.html"><i class="fa fa-check"></i><b>D</b> Generating Continuous Data</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">DSCI 551: Descriptive Statistics and Probability for Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="noteworthy-distribution-families" class="section level1">
<h1><span class="header-section-number">Lecture 8</span> Noteworthy Distribution Families</h1>
<div id="learning-objectives-6" class="section level2">
<h2><span class="header-section-number">8.1</span> Learning Objectives</h2>
<p>From today’s class, students are expected to be able to:</p>
<ul>
<li>Identify the parameterization of the multivariate Gaussian/Normal family.</li>
<li>Describe the joint density of a bivariate Gaussian distribution in terms of its contours.</li>
<li>Identify whether a bivariate Gaussian distribution has dependence or independence.</li>
<li>Compute marginal and conditional distributions from a bivariate Gaussian distribution, and compute the distribution of a linear combination of jointly Gaussian random variables.</li>
<li>Calculate the density or cdf of a mixture distribution, given the class probabilities and class distributions.</li>
</ul>
</div>
<div id="more-univariate-distribution-families-5-min" class="section level2">
<h2><span class="header-section-number">8.2</span> More Univariate Distribution Families (5 min)</h2>
<p>I added the following univariate distribution families to Lecture 6. It just fit better there, along with the other families listed there. Let’s take a look at them. They are:</p>
<ul>
<li><a href="joint-probability-part-ii.html#exponential-family">Exponential</a></li>
<li><a href="joint-probability-part-ii.html#weibull-family">Weibull</a></li>
<li><a href="joint-probability-part-ii.html#beta-family">Beta</a></li>
</ul>
</div>
<div id="multivariate-gaussiannormal-family-20-min-1" class="section level2">
<h2><span class="header-section-number">8.3</span> Multivariate Gaussian/Normal Family (20 min)</h2>
<p>We’ve already seen the Gaussian/Normal family of <em>univariate</em> distributions. There’s also a <em>multivariate</em> family of Gaussian distributions. Members of this family need to have all Gaussian marginals, and their dependence has to be “Gaussian dependence”.</p>
<p>If you’re interested, “Gaussian dependence” is obtained as a consequence of requiring that any linear combination of Gaussian random variables is also Gaussian.</p>
<div id="parameters" class="section level3">
<h3><span class="header-section-number">8.3.1</span> Parameters</h3>
<p>To characterize the <em>bivariate</em> Gaussian family, we need the following parameters:</p>
<ul>
<li>the parameters of the two marginals (mean and variance for both <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, sometimes denoted <span class="math inline">\(\mu_X, \mu_Y, \sigma^2_X, \sigma^2_Y\)</span>), and</li>
<li>the covariance between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, sometimes denoted <span class="math inline">\(\sigma_{XY}\)</span> (or, equivalently, the pearson correlation, sometimes denoted <span class="math inline">\(\rho\)</span>).</li>
</ul>
<p>That’s <strong>five parameters</strong> altogether, and only one of them (Pearson correlation or covariance) is needed to specify the dependence part.</p>
<p>Using the parameters of a bivariate Gaussian distribution, we can construct two objects that are useful for computations: a <em>mean vector</em> <span class="math inline">\(\boldsymbol{\mu}\)</span> and a <em>covariance matrix</em> <span class="math inline">\(\Sigma\)</span>, where <span class="math display">\[\boldsymbol{\mu}=\begin{pmatrix} \mu_X \\ \mu_Y \end{pmatrix},\]</span> and <span class="math display">\[\Sigma = \begin{pmatrix} \sigma_X^2 &amp; \sigma_{XY} \\ \sigma_{XY} &amp; \sigma_Y^2 \end{pmatrix}.\]</span> Even though <span class="math inline">\(\sigma_{XY}\)</span> is repeated in the upper-right and lower-left corner of <span class="math inline">\(\Sigma\)</span>, constructing the matrix in this way makes for much easier computations down the road.</p>
<p>Note that the covariance matrix is always defined as above. Even if we’re given the correlation <span class="math inline">\(\rho\)</span> instead of the covariance <span class="math inline">\(\sigma_{XY}\)</span>, we would then need to calculate the covariance (as <span class="math inline">\(\sigma_{XY} = \rho \sigma_X \sigma_Y\)</span>) before constructing the covariance matrix. However, there is another matrix that is sometimes useful, called the <strong>correlation matrix</strong>, and it’s defined as <span class="math display">\[\text{Correlation Matrix} = \begin{pmatrix} 1 &amp; \rho \\ \rho &amp; 1 \end{pmatrix}.\]</span></p>
<p>This “linear algebra” format of the parameters also makes it easier to generalize to more than two variables. In general, the <strong>multivariate Gaussian</strong> distribution made up of <span class="math inline">\(d\)</span> variables has some generic <span class="math inline">\(d\)</span>-dimensional mean vector, and a <span class="math inline">\(d \times d\)</span> covariance matrix, where the upper-right triangle and lower-right triangle of the covariance matrix are the same. This means that, to fully specify this <span class="math inline">\(d\)</span>-dimensional distribution, we need:</p>
<ul>
<li>the means and variances of all <span class="math inline">\(d\)</span> random variables, and</li>
<li>the covariance or correlations between each pair of random variables (that’s <span class="math inline">\(d \choose 2\)</span> of them).</li>
</ul>
<p>If you’re interested, it turns out any square matrix is a valid covariance matrix, so long as it’s <em>positive definite</em>. This takes care of the fact that the individual variances can’t be negative and <span class="math inline">\(-1\leq\rho\leq1\)</span>, or put another (more confusing) way, <span class="math inline">\(| Cov(X,Y) | \leq \sqrt{Var(X)Var(Y)}\)</span>. If you’d like a brief review of linear algebra, check out the Appendix.</p>
<p>Here’s an example of a covariance matrix with <span class="math inline">\(d=3\)</span> (“trivariate”), and random variables <span class="math inline">\(X, Y, Z\)</span>:</p>
<p><span class="math display">\[\Sigma=\begin{pmatrix} 
   \sigma_X^2  &amp; \sigma_{XY} &amp; \sigma_{XZ} \\ 
   \sigma_{XY} &amp; \sigma_Y^2  &amp; \sigma_{YZ}\\ 
   \sigma_{XZ} &amp; \sigma_{YZ} &amp; \sigma_Z^2 
\end{pmatrix}\]</span></p>
<p>There are overall 9 parameters needed to characterize the trivariate Gaussian family: 6 for the marginals (mean and variance per marginal), and 3 dependence parameters (all pairwise correlations).</p>
</div>
<div id="visualizing-bivariate-gaussian-density" class="section level3">
<h3><span class="header-section-number">8.3.2</span> Visualizing Bivariate Gaussian Density</h3>
<p>The joint density of multivariate Gaussian distributions have a characteristic “elliptical” shape to them. Here are some examples with <span class="math inline">\(N(0,1)\)</span> marginals, with different Pearson correlation amounts indicated in the bars:</p>
<p><img src="lecture08_files/figure-html/unnamed-chunk-2-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>And here are samples of data coming from these distributions:</p>
<p><img src="lecture08_files/figure-html/unnamed-chunk-3-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>Indeed, <em>for Gaussians specifically</em>, uncorrelated implies <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are independent. But, remember, uncorrelated often does not imply independence.</p>
<p>Let’s take a look at uncorrelated densities, but with different variances, and means of 0:</p>
<p><img src="lecture08_files/figure-html/unnamed-chunk-4-1.png" width="355.2" style="display: block; margin: auto;" /></p>
<p>Notice that elliptical contours stretched either vertically or horizontally still have no dependence! None of these do. The stretch needs to be on some diagonal in order for there to be dependence – that is, pointing in some direction other than along the x-axis or y-axis. Circular contours are both independent <em>and</em> each marginal has the same variance.</p>
<p>Note: you’ll notice the mean vector isn’t very interesting, it just shifts things around. The interesting stuff lives in <span class="math inline">\(\Sigma\)</span>.</p>
<p>Optional note: you’ll notice the contours are ellipses (ellipsoids in higher dimensions). You may recall from linear algebra class that a matrix (specifically its eigenvalues) can be thought to represent an ellipse/ellipsoid. This is the covariance matrix here – not a coincidence.</p>
</div>
<div id="properties" class="section level3">
<h3><span class="header-section-number">8.3.3</span> Properties</h3>
<p>This distribution has many amazing properties.</p>
<ol style="list-style-type: decimal">
<li><strong>Marginal distributions are Gaussian</strong>.</li>
</ol>
<p>The marginal distribution of a subset of variables can be obtained by just taking the relevant subset of means, and the relevant subset of the covariance matrix.</p>
<ol start="2" style="list-style-type: decimal">
<li><strong>Linear combinations are Gaussian</strong>.</li>
</ol>
<p>This is actually by definition. If <span class="math inline">\((X, Y)\)</span> have a bivariate Gaussian distribution, then <span class="math inline">\(aX + bY + c\)</span> for constants <span class="math inline">\(a, b, c\)</span> is Gaussian. Want to find the mean and variance? Just apply the linearity of expectations and variance rules we saw earlier: <span class="math display">\[E(aX + bY + c) = a \mu_X + b \mu_Y + c,\]</span> and <span class="math display">\[\text{Var}(aX + bY + c) = a^2 \sigma_X^2 + b^2 \sigma_Y^2 + 2ab\sigma_{XY}.\]</span> The same rules apply with more than two Gaussian random variables.</p>
<ol start="3" style="list-style-type: decimal">
<li><strong>Conditional distributions are Gaussian</strong>.</li>
</ol>
<p>If <span class="math inline">\((X, Y)\)</span> have a bivariate Gaussian distribution, then the distribution of <span class="math inline">\(Y\)</span> given that <span class="math inline">\(X = x\)</span> is also Gaussian. Its distribution is <span class="math display">\[Y\mid X = x \sim N \left(\mu_Y + \frac{\sigma_Y}{\sigma_X}\rho (x - \mu_x),\ (1 - \rho^2)\sigma_Y^2 \right)\]</span> Take a moment to notice what’s going on here:</p>
<ul>
<li>The conditional mean is linear in <span class="math inline">\(x\)</span>, passes through the mean <span class="math inline">\((\mu_X, \mu_Y)\)</span>, and has a steeper slope with higher correlation.</li>
<li>The conditional variance is smaller than the marginal variance, and gets smaller with higher correlation.</li>
</ul>
<p>Here are the conditional means (“regression line”) and 90% prediction intervals for the previous plots of bivariate Gaussians with different correlations. Note that the regression line does not actually pass through the ellipse from “tip to tip”, except in the independent case!</p>
<p><img src="lecture08_files/figure-html/unnamed-chunk-5-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>If you want to know the formula for conditional distributions in the general multivariate case, you can find this pretty easily online (c.f. <a href="https://en.wikipedia.org/wiki/Multivariate_normal_distribution#Conditional_distributions">Wikipedia</a>). It involves matrix algebra with the covariance matrix and mean vector.</p>
</div>
<div id="activity-2" class="section level3">
<h3><span class="header-section-number">8.3.4</span> Activity</h3>
<p>Consider the multivariate Gaussian distribution of random variables <span class="math inline">\(X\)</span>, <span class="math inline">\(Y\)</span>, and <span class="math inline">\(Z\)</span> with (respective) mean vector <span class="math display">\[\boldsymbol{\mu} = \begin{pmatrix} 0 \\ 2 \\ 3 \end{pmatrix},\]</span> correlation matrix <span class="math display">\[\begin{pmatrix} 
1   &amp; 0.2 &amp; 0.1 \\ 
0.2 &amp; 1   &amp; 0.2 \\ 
0.1 &amp; 0.2 &amp; 1 
\end{pmatrix},\]</span> and marginal variances of 1.</p>
<ol style="list-style-type: decimal">
<li>What’s the distribution of <span class="math inline">\(X\)</span>?</li>
<li>What’s the joint distribution of <span class="math inline">\(X\)</span> and <span class="math inline">\(Z\)</span>?</li>
<li>What’s the distribution of <span class="math inline">\(Y\)</span>, given that <span class="math inline">\(X = 0.5\)</span>?</li>
<li>What’s the distribution of <span class="math inline">\(Y - 3X\)</span>?</li>
<li>What’s <span class="math inline">\(P(Y &lt; 3X)\)</span>?</li>
</ol>
</div>
</div>
<div id="break-and-evaluations-8-min" class="section level2">
<h2><span class="header-section-number">8.4</span> Break and Evaluations (8 min)</h2>
<p>We’ll take a bit of a longer break so that you can fill in instructor evaluations. Please fill them out online (you should have received an email).</p>
</div>
<div id="mixture-distributions-20-min" class="section level2">
<h2><span class="header-section-number">8.5</span> Mixture distributions (20 min)</h2>
<p>In Lecture 3 (Simulations), we used simulation to find the distribution of a random variable that involves multiple steps. We saw at least two examples of this:</p>
<ul>
<li>The total gang demand on a given day for ships arriving at port:
<ol style="list-style-type: decimal">
<li>Generate the number of ships arriving at port on a given day.</li>
<li>For each ship, generate a gang demand.</li>
</ol></li>
<li>From your lab, the total number of cupcakes you’ll need at a party:
<ol style="list-style-type: decimal">
<li>Generate attendance to a party from a guestlist.</li>
<li>For each person attending, generate the number of cupcakes eaten.</li>
</ol></li>
</ul>
<p>There’s an important type of multiple-step distribution called a <strong>mixture distribution</strong>, that shows up in many applications. In general, a mixture distribution results if an outcome is generated as follows:</p>
<ol style="list-style-type: decimal">
<li>Generate a “membership” into one of <span class="math inline">\(k\)</span> possible classes <span class="math inline">\(A_1, \ldots, A_k\)</span>, each having probabilities <span class="math inline">\(p_1, \ldots, p_k\)</span>.</li>
<li>Each class has its own distribution; generate an observation from the corresponding distribution.</li>
</ol>
<p>If the individual distributions in Step 2 have pdf’s/pmf’s <span class="math inline">\(f_1, \ldots, f_k\)</span>, then it turns out the pdf/pmf <span class="math inline">\(f_{\text{Mixture}}\)</span> of an outcome generated by these two steps can be calculated by <span class="math display">\[f_{\text{Mixture}}(x) = p_1 f_1(x) + \cdots + p_k f_k(x).\]</span> This is true whether or not the pdf’s/pmf’s are univariate or multivariate! We also have a similar result for cdf’s. If <span class="math inline">\(F_1, \ldots, F_k\)</span> are the cdf’s corresponding to <span class="math inline">\(f_1, \ldots, f_k\)</span>, then the cdf of the mixture distribution can be calculated by <span class="math display">\[F_{\text{Mixture}}(x) = p_1 F_1(x) + \cdots + p_k F_k(x).\]</span></p>
<p>As usual, this formula isn’t a “new rule” in probability – in fact, we can derive the above formula using the law of total probability. But, we won’t require that for this course.</p>
<div id="example-mixture-of-gaussians" class="section level3">
<h3><span class="header-section-number">8.5.1</span> Example: Mixture of Gaussians</h3>
<p>A common example of a mixture distribution is a mixture of Gaussians, where each of the distribution classes <span class="math inline">\(f_1, \ldots, f_k\)</span> are Gaussian distributions (whether univariate or multivariate).</p>
<p><strong>Univariate Example</strong>: Normally, the time it takes you to commute to work (in minutes) follows a <span class="math inline">\(N(20, 16)\)</span> distribution. But, there’s a whopping 20% chance that there’ll be a collision along the way that will slow you down, in which case it will take you <span class="math inline">\(N(40, 25)\)</span> minutes to get to work. What’s the distribution?</p>
<p>Here’s a function to do the simulation, and some sample commute times:</p>
<pre><code>##  [1] 36.56652 33.33859 28.53662 22.88209 13.04609 24.66753 20.66765
##  [8] 18.61433 20.92518 21.87665</code></pre>
<p>Here’s the density function:</p>
<p>Sanity check: let’s see that the theoretical density matches the empirical density (after generating 2000 points):</p>
<p><img src="lecture08_files/figure-html/unnamed-chunk-8-1.png" width="768" style="display: block; margin: auto;" /></p>
</div>
<div id="application-clustering" class="section level3">
<h3><span class="header-section-number">8.5.2</span> Application: Clustering</h3>
<p>Consider the <code>faithful</code> data set that comes with the <code>datasets</code> package in R.</p>
<p><img src="lecture08_files/figure-html/unnamed-chunk-9-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>There appears to be two categories of eruptions here. Can we group these into clusters? This is one topic of unsupervised learning (DSCI 563) – one idea is to fit a Gaussian mixture, such as the one depicted below underneath the data.</p>
<p><img src="lecture08_files/figure-html/unnamed-chunk-10-1.png" width="576" style="display: block; margin: auto;" /></p>
</div>
<div id="application-zero-inflated-models" class="section level3">
<h3><span class="header-section-number">8.5.3</span> Application: Zero-Inflated Models</h3>
<p>Consider the following (made up) data of total rainfall for each day in September:</p>
<table>
<thead>
<tr class="header">
<th align="right">Sun</th>
<th align="right">Mon</th>
<th align="right">Tue</th>
<th align="right">Wed</th>
<th align="right">Thu</th>
<th align="right">Fri</th>
<th align="right">Sat</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0.0</td>
<td align="right">0.0</td>
<td align="right">0.0</td>
<td align="right">1.7</td>
<td align="right">0</td>
<td align="right">11.8</td>
<td align="right">3.2</td>
</tr>
<tr class="even">
<td align="right">1.5</td>
<td align="right">2.8</td>
<td align="right">0.0</td>
<td align="right">0.0</td>
<td align="right">0</td>
<td align="right">19.8</td>
<td align="right">0.0</td>
</tr>
<tr class="odd">
<td align="right">5.0</td>
<td align="right">0.0</td>
<td align="right">0.2</td>
<td align="right">1.6</td>
<td align="right">0</td>
<td align="right">1.0</td>
<td align="right">5.1</td>
</tr>
<tr class="even">
<td align="right">0.0</td>
<td align="right">3.6</td>
<td align="right">0.0</td>
<td align="right">0.0</td>
<td align="right">0</td>
<td align="right">0.0</td>
<td align="right">0.0</td>
</tr>
<tr class="odd">
<td align="right">6.3</td>
<td align="right">0.0</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
<td align="right">NA</td>
</tr>
</tbody>
</table>
<p>This isn’t quite continuous data, because 0 mm of rain is possible. Yet, the data aren’t discrete, because there are uncountably many outcomes in the case that it <em>is</em> raining.</p>
<p>The idea is to make a <strong>zero-inflation model</strong>:</p>
<ol style="list-style-type: decimal">
<li>Rain either happens or it doesn’t;</li>
<li>If no rain, then a value of 0 is taken; if there is rain, then a value is drawn from some distribution (like Weibull or Exponential).</li>
</ol>
<p>Since this random variable is <em>neither continuous nor discrete</em>, it has neither a pmf nor a pdf. But it does have a cdf. Suppose:</p>
<ul>
<li>there’s a 0.4 chance of rain, and</li>
<li>if it is raining, then the amount of rain follows an Exponential distribution with a mean of 5mm.</li>
</ul>
<p>Then we have the following cdf:</p>
<p><img src="lecture08_files/figure-html/unnamed-chunk-12-1.png" width="288" style="display: block; margin: auto;" /></p>
</div>
<div id="application-bayesian-statistics" class="section level3">
<h3><span class="header-section-number">8.5.4</span> Application: Bayesian Statistics</h3>
<p>Let’s return to our Mario Kart example. It turns out that the item distribution changes depending on how close you are to being in the lead. Let’s suppose these are the item distributions for getting an item when you’re in first, second, and third place (notice there are new items you can get!). Let’s call <span class="math inline">\(f_1(x)\)</span>, <span class="math inline">\(f_2(x)\)</span>, and <span class="math inline">\(f_3(x)\)</span> the corresponding item pmf’s.</p>
<table style="width:44%;">
<colgroup>
<col width="9%" />
<col width="9%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
</colgroup>
<thead>
<tr class="header">
<th>Item</th>
<th>Name</th>
<th>Probability: 1st place, <span class="math inline">\(f_1(x)\)</span></th>
<th>Probability: 2nd place, <span class="math inline">\(f_2(x)\)</span></th>
<th>Probability: 3rd place, <span class="math inline">\(f_3(x)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><img src="img/banana.png" /></td>
<td>Banana</td>
<td>0.12</td>
<td>0.22</td>
<td>0.10</td>
</tr>
<tr class="even">
<td><img src="img/bobomb.png" /></td>
<td>Bob-omb</td>
<td>0.05</td>
<td>0</td>
<td>0.05</td>
</tr>
<tr class="odd">
<td><img src="img/coin.png" /></td>
<td>Coin</td>
<td>0.75</td>
<td>0.22</td>
<td>0.10</td>
</tr>
<tr class="even">
<td><img src="img/horn.png" /></td>
<td>Horn</td>
<td>0.03</td>
<td>0.03</td>
<td>0.10</td>
</tr>
<tr class="odd">
<td><img src="img/shell.png" /></td>
<td>Shell</td>
<td>0.05</td>
<td>0.20</td>
<td>0.10</td>
</tr>
<tr class="even">
<td><img src="img/red.png" /></td>
<td>Red shell</td>
<td>0</td>
<td>0.30</td>
<td>0.30</td>
</tr>
<tr class="odd">
<td><img src="img/mushroom.png" /></td>
<td>Mushroom</td>
<td>0</td>
<td>0.03</td>
<td>0.25</td>
</tr>
</tbody>
</table>
<p>You’re a good player, so you never find yourself getting an item when you’re less than third place. In fact, the probability of being in first, second, and third places when getting an item are as follows:</p>
<table>
<thead>
<tr class="header">
<th>Place</th>
<th>Probability</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1st</td>
<td>0.7</td>
</tr>
<tr class="even">
<td>2nd</td>
<td>0.2</td>
</tr>
<tr class="odd">
<td>3rd</td>
<td>0.1</td>
</tr>
</tbody>
</table>
<p>The overall item distribution is a mixture distribution. Let <span class="math inline">\(X\)</span> be the item you end up getting, <span class="math inline">\(p_1, \ldots, p_3\)</span> be the placing probabilities, and <span class="math inline">\(f_1, \ldots, f_3\)</span> be the item distributions. Then, <span class="math display">\[P(X = x) = p_1 f_1(x) + p_2 f_2(x) + p_3 f_3(x),\]</span> where <span class="math inline">\(x\)</span> is one of the items (like “mushroom”, “horn”, etc.).</p>
<p>We can also view this distribution in two steps:</p>
<ol style="list-style-type: decimal">
<li>Simulate your placing;</li>
<li>Simulate from the corresponding item distribution.</li>
</ol>
<p>Here’s the mixture distribution compared with the individual distributions</p>
<p><img src="lecture08_files/figure-html/unnamed-chunk-13-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>It’s not as obvious that this is a mixture distribution when comparing to the Gaussian mixture or the zero-inflated model, but it indeed is.</p>
<p>Let’s now consider the reverse situation. Here are 100 items that a player has collected:</p>
<p><img src="lecture08_files/figure-html/unnamed-chunk-14-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>How often is this person in 1st place? 2nd place? 3rd place? There are more than 3 possible places, but let’s just consider three to simplify discussions. The idea is to start with <strong>prior probabilities</strong> for each placing – probably 1/3 for each place, especially if you don’t know the player. Then compute the <strong>posterior probabilities</strong>, which are the probabilities of each placing <em>given the data</em>. See the Appendix for Bayes’ Theorem.</p>
</div>
<div id="activity-3" class="section level3">
<h3><span class="header-section-number">8.5.5</span> Activity</h3>
<p>Recall the probability of getting a banana in Mario Kart based on placing:</p>
<table style="width:44%;">
<colgroup>
<col width="9%" />
<col width="9%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
</colgroup>
<thead>
<tr class="header">
<th>Item</th>
<th>Name</th>
<th>Probability: 1st place</th>
<th>Probability: 2nd place</th>
<th>Probability: 3rd place</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><img src="img/banana.png" /></td>
<td>Banana</td>
<td>0.12</td>
<td>0.22</td>
<td>0.10</td>
</tr>
</tbody>
</table>
<ol style="list-style-type: decimal">
<li>You’re equally likely to be in 1st, 2nd, or 3rd place. What’s the mixture distribution of the binary variable of getting a banana or not?</li>
<li>You’re <em>always</em> in first place. What’s the mixture distribution of getting a banana or not?</li>
</ol>
<table>
<tbody>
<tr class="odd">
<td><strong>END OF QUIZ 2 MATERIAL</strong></td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="topics-in-the-appendix" class="section level2">
<h2><span class="header-section-number">8.6</span> Topics in the Appendix</h2>
<p>Let’s use the remaining time to check out some topics in the Appendix. We’ll look at them in order of importance:</p>
<ol style="list-style-type: decimal">
<li>Bayes’ Theorem</li>
<li>Heavy-tailed distributions</li>
<li>Generating Continuous data</li>
</ol>

</div>
</div>



            </section>

          </div>
        </div>
      </div>
<a href="dependence.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="linear-algebra-review.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.ubc.ca/MDS-2019-20/DSCI_551_stat-prob-dsci_students/edit/master/lecture08.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
