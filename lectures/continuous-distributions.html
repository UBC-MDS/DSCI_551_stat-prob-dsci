<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Lecture 5 Continuous Distributions | DSCI 551: Descriptive Statistics and Probability for Data Science</title>
  <meta name="description" content="Lecture notes for DSCI 551 for the 2019/20 academic year." />
  <meta name="generator" content="bookdown 0.11 and GitBook 2.6.7" />

  <meta property="og:title" content="Lecture 5 Continuous Distributions | DSCI 551: Descriptive Statistics and Probability for Data Science" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Lecture notes for DSCI 551 for the 2019/20 academic year." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Lecture 5 Continuous Distributions | DSCI 551: Descriptive Statistics and Probability for Data Science" />
  
  <meta name="twitter:description" content="Lecture notes for DSCI 551 for the 2019/20 academic year." />
  

<meta name="author" content="Vincenzo Coia and Michael Gelbart" />


<meta name="date" content="2019-10-07" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="joint-probability-part-i.html">
<link rel="next" href="joint-probability-part-ii.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script src="libs/htmlwidgets-1.3/htmlwidgets.js"></script>
<link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="libs/datatables-binding-0.9/datatables.js"></script>
<link href="libs/dt-core-1.10.19/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="libs/dt-core-1.10.19/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="libs/dt-core-1.10.19/js/jquery.dataTables.min.js"></script>
<link href="libs/crosstalk-1.0.0/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.0.0/js/crosstalk.min.js"></script>


<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">DSCI 551 @ UBC 2019-20</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Lecture Notes</a></li>
<li class="chapter" data-level="1" data-path="depicting-uncertainty.html"><a href="depicting-uncertainty.html"><i class="fa fa-check"></i><b>1</b> Depicting Uncertainty</a><ul>
<li class="chapter" data-level="1.1" data-path="depicting-uncertainty.html"><a href="depicting-uncertainty.html#lecture-learning-objectives"><i class="fa fa-check"></i><b>1.1</b> Lecture Learning Objectives</a></li>
<li class="chapter" data-level="1.2" data-path="depicting-uncertainty.html"><a href="depicting-uncertainty.html#thinking-about-probability"><i class="fa fa-check"></i><b>1.2</b> Thinking about Probability</a><ul>
<li class="chapter" data-level="1.2.1" data-path="depicting-uncertainty.html"><a href="depicting-uncertainty.html#defining-probability-5-min"><i class="fa fa-check"></i><b>1.2.1</b> Defining Probability (5 min)</a></li>
<li class="chapter" data-level="1.2.2" data-path="depicting-uncertainty.html"><a href="depicting-uncertainty.html#calculating-probabilities-using-logic"><i class="fa fa-check"></i><b>1.2.2</b> Calculating Probabilities using Logic</a></li>
<li class="chapter" data-level="1.2.3" data-path="depicting-uncertainty.html"><a href="depicting-uncertainty.html#comparing-probabilities-8-min"><i class="fa fa-check"></i><b>1.2.3</b> Comparing Probabilities (8 min)</a></li>
<li class="chapter" data-level="1.2.4" data-path="depicting-uncertainty.html"><a href="depicting-uncertainty.html#interpreting-probability-5-min"><i class="fa fa-check"></i><b>1.2.4</b> Interpreting Probability (5 min)</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="depicting-uncertainty.html"><a href="depicting-uncertainty.html#probability-distributions"><i class="fa fa-check"></i><b>1.3</b> Probability Distributions</a><ul>
<li class="chapter" data-level="1.3.1" data-path="depicting-uncertainty.html"><a href="depicting-uncertainty.html#examples-of-probability-distributions-3-min"><i class="fa fa-check"></i><b>1.3.1</b> Examples of Probability Distributions (3 min)</a></li>
<li class="chapter" data-level="1.3.2" data-path="depicting-uncertainty.html"><a href="depicting-uncertainty.html#measures-of-central-tendency-and-uncertainty"><i class="fa fa-check"></i><b>1.3.2</b> Measures of central tendency and uncertainty</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="parametric-families.html"><a href="parametric-families.html"><i class="fa fa-check"></i><b>2</b> Parametric families</a><ul>
<li class="chapter" data-level="2.1" data-path="parametric-families.html"><a href="parametric-families.html#learning-objectives"><i class="fa fa-check"></i><b>2.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="2.2" data-path="parametric-families.html"><a href="parametric-families.html#properties-of-distributions-practice"><i class="fa fa-check"></i><b>2.2</b> Properties of Distributions: Practice</a><ul>
<li class="chapter" data-level="2.2.1" data-path="parametric-families.html"><a href="parametric-families.html#demonstration-example-computation-8-min"><i class="fa fa-check"></i><b>2.2.1</b> Demonstration: Example computation (8 min)</a></li>
<li class="chapter" data-level="2.2.2" data-path="parametric-families.html"><a href="parametric-families.html#activity-comparing-variance-to-entropy-12-min"><i class="fa fa-check"></i><b>2.2.2</b> Activity: Comparing Variance to Entropy (12 min)</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="parametric-families.html"><a href="parametric-families.html#expectations-of-transformations"><i class="fa fa-check"></i><b>2.3</b> Expectations of Transformations</a><ul>
<li class="chapter" data-level="2.3.1" data-path="parametric-families.html"><a href="parametric-families.html#linearity-of-expectations-5-min"><i class="fa fa-check"></i><b>2.3.1</b> Linearity of Expectations (5 min)</a></li>
<li class="chapter" data-level="2.3.2" data-path="parametric-families.html"><a href="parametric-families.html#probability-as-an-expectation-3-min"><i class="fa fa-check"></i><b>2.3.2</b> Probability as an Expectation (3 min)</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="parametric-families.html"><a href="parametric-families.html#distribution-families"><i class="fa fa-check"></i><b>2.4</b> Distribution Families</a><ul>
<li class="chapter" data-level="2.4.1" data-path="parametric-families.html"><a href="parametric-families.html#binomial-distribution-8-min"><i class="fa fa-check"></i><b>2.4.1</b> <a href="https://en.wikipedia.org/wiki/Binomial_distribution">Binomial</a> Distribution (8 min)</a></li>
<li class="chapter" data-level="2.4.2" data-path="parametric-families.html"><a href="parametric-families.html#families-vs.distributions-3-min"><i class="fa fa-check"></i><b>2.4.2</b> Families vs.Â distributions (3 min)</a></li>
<li class="chapter" data-level="2.4.3" data-path="parametric-families.html"><a href="parametric-families.html#parameters-5-min"><i class="fa fa-check"></i><b>2.4.3</b> Parameters (5 min)</a></li>
<li class="chapter" data-level="2.4.4" data-path="parametric-families.html"><a href="parametric-families.html#parameterization-8-min"><i class="fa fa-check"></i><b>2.4.4</b> Parameterization (8 min)</a></li>
<li class="chapter" data-level="2.4.5" data-path="parametric-families.html"><a href="parametric-families.html#distribution-families-in-practice"><i class="fa fa-check"></i><b>2.4.5</b> Distribution Families in Practice</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="parametric-families.html"><a href="parametric-families.html#common-distribution-families-12-min"><i class="fa fa-check"></i><b>2.5</b> Common Distribution Families (12 min)</a><ul>
<li class="chapter" data-level="2.5.1" data-path="parametric-families.html"><a href="parametric-families.html#geometric"><i class="fa fa-check"></i><b>2.5.1</b> <a href="https://en.wikipedia.org/wiki/Geometric_distribution">Geometric</a></a></li>
<li class="chapter" data-level="2.5.2" data-path="parametric-families.html"><a href="parametric-families.html#negative-binomial"><i class="fa fa-check"></i><b>2.5.2</b> <a href="https://en.wikipedia.org/wiki/Negative_binomial_distribution">Negative Binomial</a></a></li>
<li class="chapter" data-level="2.5.3" data-path="parametric-families.html"><a href="parametric-families.html#poisson"><i class="fa fa-check"></i><b>2.5.3</b> <a href="https://en.wikipedia.org/wiki/Poisson_distribution">Poisson</a></a></li>
<li class="chapter" data-level="2.5.4" data-path="parametric-families.html"><a href="parametric-families.html#bernoulli"><i class="fa fa-check"></i><b>2.5.4</b> <a href="https://en.wikipedia.org/wiki/Bernoulli_distribution">Bernoulli</a></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="simulation.html"><a href="simulation.html"><i class="fa fa-check"></i><b>3</b> Simulation</a><ul>
<li class="chapter" data-level="3.1" data-path="simulation.html"><a href="simulation.html#learning-objectives-1"><i class="fa fa-check"></i><b>3.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="3.2" data-path="simulation.html"><a href="simulation.html#review-activity-15-min"><i class="fa fa-check"></i><b>3.2</b> Review Activity (15 min)</a></li>
<li class="chapter" data-level="3.3" data-path="simulation.html"><a href="simulation.html#random-samples-terminology-5-min"><i class="fa fa-check"></i><b>3.3</b> Random Samples: Terminology (5 min)</a></li>
<li class="chapter" data-level="3.4" data-path="simulation.html"><a href="simulation.html#seeds-5-min"><i class="fa fa-check"></i><b>3.4</b> Seeds (5 min)</a></li>
<li class="chapter" data-level="3.5" data-path="simulation.html"><a href="simulation.html#generating-random-samples-code"><i class="fa fa-check"></i><b>3.5</b> Generating Random Samples: Code</a><ul>
<li class="chapter" data-level="3.5.1" data-path="simulation.html"><a href="simulation.html#from-finite-number-of-categories-5-min"><i class="fa fa-check"></i><b>3.5.1</b> From Finite Number of Categories (5 min)</a></li>
<li class="chapter" data-level="3.5.2" data-path="simulation.html"><a href="simulation.html#from-distribution-families-5-min"><i class="fa fa-check"></i><b>3.5.2</b> From Distribution Families (5 min)</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="simulation.html"><a href="simulation.html#running-simulations"><i class="fa fa-check"></i><b>3.6</b> Running Simulations</a><ul>
<li class="chapter" data-level="3.6.1" data-path="simulation.html"><a href="simulation.html#code-for-empirical-quantities-0-min"><i class="fa fa-check"></i><b>3.6.1</b> Code for empirical quantities (0 min)</a></li>
<li class="chapter" data-level="3.6.2" data-path="simulation.html"><a href="simulation.html#basic-simulation-10-min"><i class="fa fa-check"></i><b>3.6.2</b> Basic Simulation (10 min)</a></li>
<li class="chapter" data-level="3.6.3" data-path="simulation.html"><a href="simulation.html#multi-step-simulations-10-min"><i class="fa fa-check"></i><b>3.6.3</b> Multi-Step Simulations (10 min)</a></li>
<li class="chapter" data-level="3.6.4" data-path="simulation.html"><a href="simulation.html#mixture-distributions"><i class="fa fa-check"></i><b>3.6.4</b> Mixture distributions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="joint-probability-part-i.html"><a href="joint-probability-part-i.html"><i class="fa fa-check"></i><b>4</b> Joint Probability, Part I</a><ul>
<li class="chapter" data-level="4.1" data-path="joint-probability-part-i.html"><a href="joint-probability-part-i.html#learning-objectives-2"><i class="fa fa-check"></i><b>4.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="4.2" data-path="joint-probability-part-i.html"><a href="joint-probability-part-i.html#conditional-distributions-15-min"><i class="fa fa-check"></i><b>4.2</b> Conditional Distributions (15 min)</a></li>
<li class="chapter" data-level="4.3" data-path="joint-probability-part-i.html"><a href="joint-probability-part-i.html#joint-distributions-25-min"><i class="fa fa-check"></i><b>4.3</b> Joint Distributions (25 min)</a><ul>
<li class="chapter" data-level="4.3.1" data-path="joint-probability-part-i.html"><a href="joint-probability-part-i.html#example-length-of-stay-vs.gang-demand"><i class="fa fa-check"></i><b>4.3.1</b> Example: Length of Stay vs.Â Gang Demand</a></li>
<li class="chapter" data-level="4.3.2" data-path="joint-probability-part-i.html"><a href="joint-probability-part-i.html#marginal-distributions"><i class="fa fa-check"></i><b>4.3.2</b> Marginal Distributions</a></li>
<li class="chapter" data-level="4.3.3" data-path="joint-probability-part-i.html"><a href="joint-probability-part-i.html#calculating-marginals-from-the-joint"><i class="fa fa-check"></i><b>4.3.3</b> Calculating Marginals from the Joint</a></li>
<li class="chapter" data-level="4.3.4" data-path="joint-probability-part-i.html"><a href="joint-probability-part-i.html#conditioning-on-one-variable"><i class="fa fa-check"></i><b>4.3.4</b> Conditioning on one Variable</a></li>
<li class="chapter" data-level="4.3.5" data-path="joint-probability-part-i.html"><a href="joint-probability-part-i.html#law-of-total-probabilityexpectation"><i class="fa fa-check"></i><b>4.3.5</b> Law of Total Probability/Expectation</a></li>
<li class="chapter" data-level="4.3.6" data-path="joint-probability-part-i.html"><a href="joint-probability-part-i.html#exercises-10-min"><i class="fa fa-check"></i><b>4.3.6</b> Exercises (10 min)</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="joint-probability-part-i.html"><a href="joint-probability-part-i.html#dependence-concepts"><i class="fa fa-check"></i><b>4.4</b> Dependence concepts</a><ul>
<li class="chapter" data-level="4.4.1" data-path="joint-probability-part-i.html"><a href="joint-probability-part-i.html#independence-5-min"><i class="fa fa-check"></i><b>4.4.1</b> Independence (5 min)</a></li>
<li class="chapter" data-level="4.4.2" data-path="joint-probability-part-i.html"><a href="joint-probability-part-i.html#measures-of-dependence-15-min"><i class="fa fa-check"></i><b>4.4.2</b> Measures of dependence (15 min)</a></li>
<li class="chapter" data-level="4.4.3" data-path="joint-probability-part-i.html"><a href="joint-probability-part-i.html#variance-of-a-sum-2-min"><i class="fa fa-check"></i><b>4.4.3</b> Variance of a sum (2 min)</a></li>
<li class="chapter" data-level="4.4.4" data-path="joint-probability-part-i.html"><a href="joint-probability-part-i.html#dependence-as-separate-from-the-marginals-5-min-optional"><i class="fa fa-check"></i><b>4.4.4</b> Dependence as separate from the marginals (5 min) (Optional)</a></li>
<li class="chapter" data-level="4.4.5" data-path="joint-probability-part-i.html"><a href="joint-probability-part-i.html#dependence-as-giving-us-more-information-5-min-optional"><i class="fa fa-check"></i><b>4.4.5</b> Dependence as giving us more information (5 min) (Optional)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="continuous-distributions.html"><a href="continuous-distributions.html"><i class="fa fa-check"></i><b>5</b> Continuous Distributions</a><ul>
<li class="chapter" data-level="5.1" data-path="continuous-distributions.html"><a href="continuous-distributions.html#roadmap"><i class="fa fa-check"></i><b>5.1</b> Roadmap</a></li>
<li class="chapter" data-level="5.2" data-path="continuous-distributions.html"><a href="continuous-distributions.html#learning-objectives-3"><i class="fa fa-check"></i><b>5.2</b> Learning Objectives</a></li>
<li class="chapter" data-level="5.3" data-path="continuous-distributions.html"><a href="continuous-distributions.html#continuous-random-variables-10-min"><i class="fa fa-check"></i><b>5.3</b> Continuous random variables (10 min)</a></li>
<li class="chapter" data-level="5.4" data-path="continuous-distributions.html"><a href="continuous-distributions.html#density-functions-20-min"><i class="fa fa-check"></i><b>5.4</b> Density Functions (20 min)</a><ul>
<li class="chapter" data-level="5.4.1" data-path="continuous-distributions.html"><a href="continuous-distributions.html#example-low-purity-octane"><i class="fa fa-check"></i><b>5.4.1</b> Example: âLow Purity Octaneâ</a></li>
<li class="chapter" data-level="5.4.2" data-path="continuous-distributions.html"><a href="continuous-distributions.html#example-monthly-expenses"><i class="fa fa-check"></i><b>5.4.2</b> Example: Monthly Expenses</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="continuous-distributions.html"><a href="continuous-distributions.html#distribution-properties-25-min"><i class="fa fa-check"></i><b>5.5</b> Distribution Properties (25 min)</a><ul>
<li class="chapter" data-level="5.5.1" data-path="continuous-distributions.html"><a href="continuous-distributions.html#mean-variance-mode-and-entropy-again-5-min"><i class="fa fa-check"></i><b>5.5.1</b> Mean, Variance, Mode, and Entropy (again) (5 min)</a></li>
<li class="chapter" data-level="5.5.2" data-path="continuous-distributions.html"><a href="continuous-distributions.html#median-5-min"><i class="fa fa-check"></i><b>5.5.2</b> Median (5 min)</a></li>
<li class="chapter" data-level="5.5.3" data-path="continuous-distributions.html"><a href="continuous-distributions.html#quantiles-5-min"><i class="fa fa-check"></i><b>5.5.3</b> Quantiles (5 min)</a></li>
<li class="chapter" data-level="5.5.4" data-path="continuous-distributions.html"><a href="continuous-distributions.html#prediction-intervals-5-min"><i class="fa fa-check"></i><b>5.5.4</b> Prediction Intervals (5 min)</a></li>
<li class="chapter" data-level="5.5.5" data-path="continuous-distributions.html"><a href="continuous-distributions.html#skewness-5-min"><i class="fa fa-check"></i><b>5.5.5</b> Skewness (5 min)</a></li>
<li class="chapter" data-level="5.5.6" data-path="continuous-distributions.html"><a href="continuous-distributions.html#examples"><i class="fa fa-check"></i><b>5.5.6</b> Examples</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html"><i class="fa fa-check"></i><b>6</b> Joint Probability, Part II</a><ul>
<li class="chapter" data-level="6.1" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html#learning-objectives-4"><i class="fa fa-check"></i><b>6.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="6.2" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html#depicting-distributions-25-min"><i class="fa fa-check"></i><b>6.2</b> Depicting Distributions (25 min)</a><ul>
<li class="chapter" data-level="6.2.1" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html#cumulative-density-functions-cdfs-distribution-functions"><i class="fa fa-check"></i><b>6.2.1</b> Cumulative Density Functions (cdfâs) / Distribution Functions</a></li>
<li class="chapter" data-level="6.2.2" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html#survival-function-2-min"><i class="fa fa-check"></i><b>6.2.2</b> Survival Function (2 min)</a></li>
<li class="chapter" data-level="6.2.3" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html#quantile-function-5-min"><i class="fa fa-check"></i><b>6.2.3</b> Quantile Function (5 min)</a></li>
<li class="chapter" data-level="6.2.4" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html#other-ways-of-depicting-a-distribution-optional-1-min"><i class="fa fa-check"></i><b>6.2.4</b> Other ways of depicting a distribution (Optional) (1 min)</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html#common-distribution-families-continuous-part-i-15-min"><i class="fa fa-check"></i><b>6.3</b> Common Distribution Families: Continuous, Part I (15 min)</a><ul>
<li class="chapter" data-level="6.3.1" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html#uniform-3-min"><i class="fa fa-check"></i><b>6.3.1</b> <a href="https://en.wikipedia.org/wiki/Uniform_distribution_(continuous)">Uniform</a> (3 min)</a></li>
<li class="chapter" data-level="6.3.2" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html#gaussian-normal-4-min"><i class="fa fa-check"></i><b>6.3.2</b> <a href="https://en.wikipedia.org/wiki/Normal_distribution">Gaussian / Normal</a> (4 min)</a></li>
<li class="chapter" data-level="6.3.3" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html#log-normal-family"><i class="fa fa-check"></i><b>6.3.3</b> <a href="https://en.wikipedia.org/wiki/Log-normal_distribution">Log-Normal</a> Family</a></li>
<li class="chapter" data-level="6.3.4" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html#exponential-family"><i class="fa fa-check"></i><b>6.3.4</b> <a href="https://en.wikipedia.org/wiki/Exponential_distribution">Exponential</a> Family</a></li>
<li class="chapter" data-level="6.3.5" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html#weibull-family"><i class="fa fa-check"></i><b>6.3.5</b> <a href="https://en.wikipedia.org/wiki/Weibull_distribution">Weibull</a> Family</a></li>
<li class="chapter" data-level="6.3.6" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html#beta-family"><i class="fa fa-check"></i><b>6.3.6</b> <a href="https://en.wikipedia.org/wiki/Beta_distribution">Beta</a> Family</a></li>
<li class="chapter" data-level="6.3.7" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html#relevant-r-functions-8-min"><i class="fa fa-check"></i><b>6.3.7</b> Relevant R functions (8 min)</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html#multivariate-distributions-continuous-20-min"><i class="fa fa-check"></i><b>6.4</b> Multivariate Distributions: Continuous (20 min)</a><ul>
<li class="chapter" data-level="6.4.1" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html#multivariate-densitiespdfs"><i class="fa fa-check"></i><b>6.4.1</b> Multivariate Densities/pdfâs</a></li>
<li class="chapter" data-level="6.4.2" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html#calculating-probabilities"><i class="fa fa-check"></i><b>6.4.2</b> Calculating Probabilities</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html#conditional-distributions-revisited-15-min"><i class="fa fa-check"></i><b>6.5</b> Conditional Distributions, revisited (15 min)</a><ul>
<li class="chapter" data-level="6.5.1" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html#when-pa-0"><i class="fa fa-check"></i><b>6.5.1</b> When <span class="math inline">\(P(A) = 0\)</span></a></li>
<li class="chapter" data-level="6.5.2" data-path="joint-probability-part-ii.html"><a href="joint-probability-part-ii.html#when-pb-0"><i class="fa fa-check"></i><b>6.5.2</b> When <span class="math inline">\(P(B) = 0\)</span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="dependence.html"><a href="dependence.html"><i class="fa fa-check"></i><b>7</b> Dependence</a><ul>
<li class="chapter" data-level="7.1" data-path="dependence.html"><a href="dependence.html#learning-objectives-5"><i class="fa fa-check"></i><b>7.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="7.2" data-path="dependence.html"><a href="dependence.html#drawing-multidimensional-functions-5-min"><i class="fa fa-check"></i><b>7.2</b> Drawing multidimensional functions (5 min)</a><ul>
<li class="chapter" data-level="7.2.1" data-path="dependence.html"><a href="dependence.html#a-possible-point-of-confusion-empirical-contour-plots"><i class="fa fa-check"></i><b>7.2.1</b> A possible point of confusion: empirical contour plots</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="dependence.html"><a href="dependence.html#independence-revisited-10-min"><i class="fa fa-check"></i><b>7.3</b> Independence Revisited (10 min)</a><ul>
<li class="chapter" data-level="7.3.1" data-path="dependence.html"><a href="dependence.html#definition-in-the-continuous-case"><i class="fa fa-check"></i><b>7.3.1</b> Definition in the Continuous Case</a></li>
<li class="chapter" data-level="7.3.2" data-path="dependence.html"><a href="dependence.html#independence-visualized"><i class="fa fa-check"></i><b>7.3.2</b> Independence Visualized</a></li>
<li class="chapter" data-level="7.3.3" data-path="dependence.html"><a href="dependence.html#activity"><i class="fa fa-check"></i><b>7.3.3</b> Activity</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="dependence.html"><a href="dependence.html#harvesting-dependence-20-min"><i class="fa fa-check"></i><b>7.4</b> Harvesting Dependence (20 min)</a><ul>
<li class="chapter" data-level="7.4.1" data-path="dependence.html"><a href="dependence.html#example-river-flow"><i class="fa fa-check"></i><b>7.4.1</b> Example: River Flow</a></li>
<li class="chapter" data-level="7.4.2" data-path="dependence.html"><a href="dependence.html#direction-of-dependence"><i class="fa fa-check"></i><b>7.4.2</b> Direction of Dependence</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="dependence.html"><a href="dependence.html#marginal-distributions-20-min"><i class="fa fa-check"></i><b>7.5</b> Marginal Distributions (20 min)</a><ul>
<li class="chapter" data-level="7.5.1" data-path="dependence.html"><a href="dependence.html#marginal-distribution-from-conditional"><i class="fa fa-check"></i><b>7.5.1</b> Marginal Distribution from Conditional</a></li>
<li class="chapter" data-level="7.5.2" data-path="dependence.html"><a href="dependence.html#marginal-mean-from-conditional"><i class="fa fa-check"></i><b>7.5.2</b> Marginal Mean from Conditional</a></li>
<li class="chapter" data-level="7.5.3" data-path="dependence.html"><a href="dependence.html#marginal-quantiles-from-conditional"><i class="fa fa-check"></i><b>7.5.3</b> Marginal Quantiles from Conditional</a></li>
<li class="chapter" data-level="7.5.4" data-path="dependence.html"><a href="dependence.html#activity-1"><i class="fa fa-check"></i><b>7.5.4</b> Activity</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="dependence.html"><a href="dependence.html#multivariate-gaussiannormal-family-20-min"><i class="fa fa-check"></i><b>7.6</b> Multivariate Gaussian/Normal Family (20 min)</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="noteworthy-distribution-families.html"><a href="noteworthy-distribution-families.html"><i class="fa fa-check"></i><b>8</b> Noteworthy Distribution Families</a><ul>
<li class="chapter" data-level="8.1" data-path="noteworthy-distribution-families.html"><a href="noteworthy-distribution-families.html#learning-objectives-6"><i class="fa fa-check"></i><b>8.1</b> Learning Objectives</a></li>
<li class="chapter" data-level="8.2" data-path="noteworthy-distribution-families.html"><a href="noteworthy-distribution-families.html#more-univariate-distribution-families-5-min"><i class="fa fa-check"></i><b>8.2</b> More Univariate Distribution Families (5 min)</a></li>
<li class="chapter" data-level="8.3" data-path="noteworthy-distribution-families.html"><a href="noteworthy-distribution-families.html#multivariate-gaussiannormal-family-20-min-1"><i class="fa fa-check"></i><b>8.3</b> Multivariate Gaussian/Normal Family (20 min)</a><ul>
<li class="chapter" data-level="8.3.1" data-path="noteworthy-distribution-families.html"><a href="noteworthy-distribution-families.html#parameters"><i class="fa fa-check"></i><b>8.3.1</b> Parameters</a></li>
<li class="chapter" data-level="8.3.2" data-path="noteworthy-distribution-families.html"><a href="noteworthy-distribution-families.html#visualizing-bivariate-gaussian-density"><i class="fa fa-check"></i><b>8.3.2</b> Visualizing Bivariate Gaussian Density</a></li>
<li class="chapter" data-level="8.3.3" data-path="noteworthy-distribution-families.html"><a href="noteworthy-distribution-families.html#properties"><i class="fa fa-check"></i><b>8.3.3</b> Properties</a></li>
<li class="chapter" data-level="8.3.4" data-path="noteworthy-distribution-families.html"><a href="noteworthy-distribution-families.html#activity-2"><i class="fa fa-check"></i><b>8.3.4</b> Activity</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="noteworthy-distribution-families.html"><a href="noteworthy-distribution-families.html#break-and-evaluations-8-min"><i class="fa fa-check"></i><b>8.4</b> Break and Evaluations (8 min)</a></li>
<li class="chapter" data-level="8.5" data-path="noteworthy-distribution-families.html"><a href="noteworthy-distribution-families.html#mixture-distributions-20-min"><i class="fa fa-check"></i><b>8.5</b> Mixture distributions (20 min)</a><ul>
<li class="chapter" data-level="8.5.1" data-path="noteworthy-distribution-families.html"><a href="noteworthy-distribution-families.html#example-mixture-of-gaussians"><i class="fa fa-check"></i><b>8.5.1</b> Example: Mixture of Gaussians</a></li>
<li class="chapter" data-level="8.5.2" data-path="noteworthy-distribution-families.html"><a href="noteworthy-distribution-families.html#application-clustering"><i class="fa fa-check"></i><b>8.5.2</b> Application: Clustering</a></li>
<li class="chapter" data-level="8.5.3" data-path="noteworthy-distribution-families.html"><a href="noteworthy-distribution-families.html#application-zero-inflated-models"><i class="fa fa-check"></i><b>8.5.3</b> Application: Zero-Inflated Models</a></li>
<li class="chapter" data-level="8.5.4" data-path="noteworthy-distribution-families.html"><a href="noteworthy-distribution-families.html#application-bayesian-statistics"><i class="fa fa-check"></i><b>8.5.4</b> Application: Bayesian Statistics</a></li>
<li class="chapter" data-level="8.5.5" data-path="noteworthy-distribution-families.html"><a href="noteworthy-distribution-families.html#activity-3"><i class="fa fa-check"></i><b>8.5.5</b> Activity</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="noteworthy-distribution-families.html"><a href="noteworthy-distribution-families.html#topics-in-the-appendix"><i class="fa fa-check"></i><b>8.6</b> Topics in the Appendix</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix (Optional)</b></span></li>
<li class="chapter" data-level="A" data-path="linear-algebra-review.html"><a href="linear-algebra-review.html"><i class="fa fa-check"></i><b>A</b> Linear Algebra Review</a><ul>
<li class="chapter" data-level="A.1" data-path="linear-algebra-review.html"><a href="linear-algebra-review.html#review-of-vectors-and-linear-algebra"><i class="fa fa-check"></i><b>A.1</b> Review of vectors and linear algebra</a><ul>
<li class="chapter" data-level="A.1.1" data-path="linear-algebra-review.html"><a href="linear-algebra-review.html#vectors"><i class="fa fa-check"></i><b>A.1.1</b> Vectors</a></li>
<li class="chapter" data-level="A.1.2" data-path="linear-algebra-review.html"><a href="linear-algebra-review.html#matrices"><i class="fa fa-check"></i><b>A.1.2</b> Matrices</a></li>
</ul></li>
<li class="chapter" data-level="A.2" data-path="linear-algebra-review.html"><a href="linear-algebra-review.html#random-vectors"><i class="fa fa-check"></i><b>A.2</b> Random vectors</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="bayes-theorem.html"><a href="bayes-theorem.html"><i class="fa fa-check"></i><b>B</b> Bayesâ Theorem</a></li>
<li class="chapter" data-level="C" data-path="heavy-tailed-distributions.html"><a href="heavy-tailed-distributions.html"><i class="fa fa-check"></i><b>C</b> Heavy-Tailed Distributions</a><ul>
<li class="chapter" data-level="C.1" data-path="heavy-tailed-distributions.html"><a href="heavy-tailed-distributions.html#sensitivity-of-the-mean-to-extremes"><i class="fa fa-check"></i><b>C.1</b> Sensitivity of the mean to extremes</a></li>
<li class="chapter" data-level="C.2" data-path="heavy-tailed-distributions.html"><a href="heavy-tailed-distributions.html#heavy-tailed-distributions-1"><i class="fa fa-check"></i><b>C.2</b> Heavy-tailed Distributions</a></li>
<li class="chapter" data-level="C.3" data-path="heavy-tailed-distributions.html"><a href="heavy-tailed-distributions.html#heavy-tailed-distribution-families"><i class="fa fa-check"></i><b>C.3</b> Heavy-tailed distribution families</a></li>
<li class="chapter" data-level="C.4" data-path="heavy-tailed-distributions.html"><a href="heavy-tailed-distributions.html#extreme-value-analysis"><i class="fa fa-check"></i><b>C.4</b> Extreme Value Analysis</a></li>
<li class="chapter" data-level="C.5" data-path="heavy-tailed-distributions.html"><a href="heavy-tailed-distributions.html#multivariate-students-t-distributions"><i class="fa fa-check"></i><b>C.5</b> Multivariate Studentâs <em>t</em> distributions</a></li>
</ul></li>
<li class="chapter" data-level="D" data-path="generating-continuous-data.html"><a href="generating-continuous-data.html"><i class="fa fa-check"></i><b>D</b> Generating Continuous Data</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">DSCI 551: Descriptive Statistics and Probability for Data Science</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="continuous-distributions" class="section level1">
<h1><span class="header-section-number">Lecture 5</span> Continuous Distributions</h1>
<div id="roadmap" class="section level2">
<h2><span class="header-section-number">5.1</span> Roadmap</h2>
<p>The first two weeks covered the following concepts:</p>
<ul>
<li><em>Distributions</em>, and ways of <em>describing</em> a distribution.</li>
<li><em>Simulation</em> concepts.</li>
<li><em>Bivariate</em> concepts.</li>
</ul>
<p>All of this was in the context of <em>discrete</em> random variables. For the next two weeks, we will broaden our discussion on these topics, but in the context of <em>continuous</em> random variables.</p>
</div>
<div id="learning-objectives-3" class="section level2">
<h2><span class="header-section-number">5.2</span> Learning Objectives</h2>
<p>From todayâs lecture, students should be able to:</p>
<ul>
<li>Differentiate between continuous and discrete random variables.</li>
<li>Calculate and interpret probabilistic quantities (mean, quantiles, prediction intervals, etc) for a continuous random variable</li>
<li>Match a distribution to sampled data</li>
</ul>
<p><strong>A note on integrals</strong>: Working with continuous random variables sometimes involves integrating some functions. The most we will ever ask you to integrate are functions that are linear, because they can be computed using the formula for the area of a triangle and area of a rectangle. This is not because itâs âtoo hardâ to compute integrals, but because thereâs not much pedagogical value in it, especially because weâre gearing this course towards the usefulness of probability in data science.</p>
</div>
<div id="continuous-random-variables-10-min" class="section level2">
<h2><span class="header-section-number">5.3</span> Continuous random variables (10 min)</h2>
<p>What is the current water level of the Bow River at Banff, Alberta? How tall is a tree? What about the current atmospheric temperature in Vancouver, BC? These are examples of <em>continuous</em> random variables, because there are an <em>uncountably infinite</em> amount of outcomes. Discrete random variables, on the other hand, are <em>countable</em>, even if there are infinitely many outcomes, because each outcome can be accounted for one-at-a-time by some pattern.</p>
<p><strong>Example</strong>: The positive integers are discrete/countable: just start with 1 and keep adding 1 to get 1, 2, 3, etc., and that covers all possible outcomes. Positive real numbers are not countable because thereâs no way to cover all possibilities by considering one outcome at a time.</p>
<p>It turns out that itâs trickier to interpret probabilities for continuous random variables, but it also turns out that theyâre in general easier to work with.</p>
<p>Not all random variables with infinitely many outcomes are continuous. Take, for example, a Poisson random variable, that can take values <span class="math inline">\(0, 1, 2, \ldots\)</span> with no upper limit. The difference here is that a smaller range of values <em>does</em> have a finite amount of variables. By the way, this type of infinity is called âcountably infiniteâ, and a continuous random variable has âuncountably infiniteâ amount of outcomes.</p>
<p>In practice, we can never measure anything on a continuous scale, since any measuring instrument must always round to some precision. For example, your kitchen scale might only measure things to the nearest gram. But, these variables are well approximated by a continuous variable. As a rule of thumb, if the difference between neighbouring values isnât a big deal, consider the variable continuous.</p>
<p><strong>Example</strong>:</p>
<p>Youâd like to get a handle on your monthly finances, so you record your total monthly expenses each month. You end up with 20 months worth of data:</p>
<pre><code>##  [1] &quot;$1903.68&quot; &quot;$3269.61&quot; &quot;$6594.05&quot; &quot;$1693.94&quot; &quot;$2863.71&quot; &quot;$3185.01&quot;
##  [7] &quot;$4247.04&quot; &quot;$2644.27&quot; &quot;$8040.42&quot; &quot;$2781.11&quot; &quot;$3673.23&quot; &quot;$4870.13&quot;
## [13] &quot;$2449.53&quot; &quot;$1772.53&quot; &quot;$7267.11&quot; &quot;$938.67&quot;  &quot;$4625.33&quot; &quot;$3034.81&quot;
## [19] &quot;$4946.4&quot;  &quot;$3700.16&quot;</code></pre>
<p>Since a difference of $0.01 isnât a big deal, we may as well treat this as a continuous random variable.</p>
<p><strong>Example</strong>:</p>
<p>Back in the day when Canada had pennies, you liked to play âpenny bingoâ, and wrote down your winnings after each day of playing the game with your friends. Here are your net winnings:</p>
<pre><code>##  [1]  0.01 -0.01  0.02  0.01  0.04  0.02 -0.03 -0.01  0.05  0.04</code></pre>
<p>Since a difference of $0.01 is a big deal, best to treat this as discrete.</p>
</div>
<div id="density-functions-20-min" class="section level2">
<h2><span class="header-section-number">5.4</span> Density Functions (20 min)</h2>
<p>In the discrete case, we were able to specify a distribution by indicating a probability for each outcome. Even when thereâs an infinite amount of outcomes, such as in the case of a Poisson distribution, we can still place a non-zero probability on each outcome and have the probabilities sum to 1 (thanks to <a href="https://en.wikipedia.org/wiki/Convergent_series">convergent series</a>). But an uncountable amount of outcomes cannot be all accounted for by a sum (i.e., the type of sum we denote by <span class="math inline">\(\sum\)</span>), and this means that <em>continuous outcomes must have probability 0</em>.</p>
<p><strong>Example</strong>: The probability that the temperature in Vancouver tomorrow will be 18 degrees celcius is 0. In fact, any temperature has a probability of 0 of occurring.</p>
<p>While individual outcomes have zero probability, <em>ranges</em> can have non-zero probability. We can use this idea to figure out how âdenseâ the probability is at some areas of the outcome space. For example, if a randomly selected tree has a 0.05 probability of being within 0.1m of 5.0m, then as a rate, thatâs about 0.05/(0.1m) = 0.5 âprobability per meterâ here. Taking the limit as the range width <span class="math inline">\(\rightarrow 0\)</span>, we obtain whatâs called the <strong>density</strong> at 5m.</p>
<p>The density as a function over the outcome space is called the <strong>probability density function</strong> (pdf), usually abbreviated to just the <strong>density</strong>, and denoted <span class="math inline">\(f\)</span>. Sometimes we specify the random variable in the subscript, just to be clear about what random variable this density represents â for example, <span class="math inline">\(f_X\)</span> is the density of random variable <span class="math inline">\(X\)</span>.</p>
<p>Youâll see that the density is like a âcontinuous cousinâ of the <em>probability mass function</em> (pmf) in the case of discrete random variables. Weâll also see in a future lecture that there are some random variables for which neither a density nor a pmf exist.</p>
<p>We can use the density to calculate probabilies of a range by integrating the density over that range: <span class="math display">\[P(a &lt; X &lt; b) = \int_a^b f(x) \text{d}x.\]</span> This means that, integrating over the entire range of possibilities should give us 1: <span class="math display">\[\int_{-\infty}^\infty f(x) \text{d}x = 1\]</span> This integral corresponds to the entire area under the density function.</p>
<div id="example-low-purity-octane" class="section level3">
<h3><span class="header-section-number">5.4.1</span> Example: âLow Purity Octaneâ</h3>
<p>You just ran out of gas, but luckily, right in front of a gas station! Or maybe not so lucky, since the gas station is called âLow Purity Octaneâ. They tell you that the octane purity of their gasoline is random, and has the following density:</p>
<p><img src="lecture05_files/figure-html/unnamed-chunk-4-1.png" width="288" style="display: block; margin: auto;" /></p>
<ol style="list-style-type: decimal">
<li>Whatâs the probability of getting 25% purity? That is, <span class="math inline">\(P(\text{Purity} = 0.25)\)</span>?</li>
<li>The density evaluates to be &gt;1 in some places. Does this mean that this is not a valid density? Why is the density in fact valid?</li>
<li>Is it possible for the density to be negative? Why or why not?</li>
<li>Whatâs the probability of getting gas thatâs <span class="math inline">\(&lt;50\%\)</span> pure? That is, <span class="math inline">\(P(\text{Purity} &lt; 0.5)\)</span>?</li>
<li>Whatâs the probability of getting gas thatâs <span class="math inline">\(\leq 50\%\)</span> pure? That is, <span class="math inline">\(P(\text{Purity} \leq 0.5)\)</span>?</li>
<li>Whatâs the <em>support</em> of this random variable? That is, the set of all outcomes that have non-zero density?</li>
<li>You decide to spend the day at Low Purity Octane, measuring the octane purity for each customer. You end up getting 100 observations, placing each measurement along the x-axis. Which of the following plots would be more likely, and why?</li>
</ol>
<p><img src="lecture05_files/figure-html/unnamed-chunk-5-1.png" width="768" style="display: block; margin: auto;" /></p>
</div>
<div id="example-monthly-expenses" class="section level3">
<h3><span class="header-section-number">5.4.2</span> Example: Monthly Expenses</h3>
<p>It turns out your monthly expenses have the following density, with your 20 observations plotted below it:</p>
<p><img src="lecture05_files/figure-html/unnamed-chunk-6-1.png" width="480" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="distribution-properties-25-min" class="section level2">
<h2><span class="header-section-number">5.5</span> Distribution Properties (25 min)</h2>
<p>With continuous random variables, it becomes easier to expand our âtoolkitâ of the way we describe a distribution / random variable. As before, each property always has a distribution-based definition that gives us an exact/true value, and sometimes has an empirically-based (data-based) definition that gives us an approximate value, but that approaches the true value as more and more observations are collected.</p>
<div id="mean-variance-mode-and-entropy-again-5-min" class="section level3">
<h3><span class="header-section-number">5.5.1</span> Mean, Variance, Mode, and Entropy (again) (5 min)</h3>
<p>These are the properties of a distribution that weâve already seen, but they do indeed extend to the continuous case.</p>
<p>Mode and entropy can be defined, but since these ignore the numeric property of continuous random variables, they tend to not be used. Also, these properties donât really have a natural empirical version.</p>
<ul>
<li><strong>Mode</strong>: The outcome having the highest density. That is, <span class="math display">\[\text{Mode} = {\arg \max}_x f(x).\]</span></li>
<li><strong>Entropy</strong>: The entropy can be defined by replacing the sum in the finite case with an integral: <span class="math display">\[\text{Entropy} = \int_x f(x) \log f(x) \text{d}x.\]</span></li>
</ul>
<p>Instead, we prefer to describe a continuous random variable using properties that inform us about distances. The mean and variance are two such measures of central tendency and uncertainty, where the only difference with a continuous random variable is in the distribution-based definition, where the sum becomes an integral.</p>
<ul>
<li><strong>Mean</strong>: The distribution-based definition is <span class="math display">\[E(X) = \int_x x \, f(x) \text{d}x.\]</span></li>
<li>You may later learn that this is a point that is âas close as possibleâ to a randomly generated outcome, in the sense that its expected squared distance is as small as possible.</li>
<li>Ends up being the âcenter of massâ of a probability density function, meaning that you could âbalanceâ the density function on this single point without it âtoppling over due to gravityâ.</li>
<li>Probably best interpreted as the long-run sample average (empirical mean).</li>
<li><strong>Variance</strong>: The distribution-based definition is <span class="math display">\[\text{Var}(X) = E \left( (X - \mu_X)^2 \right) = \int_x (x - \mu_X) ^ 2 \, f(x) \text{d}x,\]</span> where <span class="math inline">\(\mu_X = E(X)\)</span>. While the mean minimizes the expected squared distance to a randomly generated outcome, this <em>is</em> the expected squared distance.</li>
</ul>
<p>Going back to the octane purity example from Low Purity Octane gas station:</p>
<ul>
<li>The mode is 1 (the highest purity possible!).</li>
<li>The entropy works out to be <span class="math display">\[\int_0^1 2x \log(2x) \text{d}x \doteq 0.1931.\]</span></li>
<li>The mean ends up being not a very good purity (especially as compared to the mode!), and is <span class="math display">\[\int_0^1 2x^2 \text{d}x = \frac{2}{3}.\]</span></li>
<li>The variance ends up being <span class="math display">\[\int_0^1 2 x \left(x - \frac{2}{3}\right)^2 \text{d}x = \frac{1}{18}.\]</span></li>
</ul>
</div>
<div id="median-5-min" class="section level3">
<h3><span class="header-section-number">5.5.2</span> Median (5 min)</h3>
<p>The median is the outcome for which thereâs a 50-50 chance of seeing a greater or lesser value. So, its distribution-based definition satisfies <span class="math display">\[P(X \leq \text{Median}(X)) = 0.5.\]</span> Its empirically-based definition is the âmiddle valueâ after sorting the outcomes from left-to-right.</p>
<p>Similar to the mean, you may later learn that the median is a point that is âas close as possibleâ to a randomly generated outcome, in the sense that its expected <em>absolute</em> distance is as small as possible.</p>
<p>The median is perhaps best for making a single decision about a random outcome. Making a decision is simplest when the possibilities are reduced down to two equally likely outcomes, and this is exactly what the median does. For example, if the median time it takes to complete a hike is 2 hours, then you know that thereâs a 50-50 chance that the hike will take over 2 hours. If youâre instead told that the mean is 2 hours, this only tells us that the total amount of hiking time done by a bunch of people will be as if everyone takes 2 hours to do the hike â this is still useful for making a decision about whether or not you should do the hike, but is more convoluted.</p>
<p>Using the purity example at Low Purity Octane, the median is about 0.7071:</p>
<p><img src="lecture05_files/figure-html/unnamed-chunk-7-1.png" width="384" style="display: block; margin: auto;" /></p>
</div>
<div id="quantiles-5-min" class="section level3">
<h3><span class="header-section-number">5.5.3</span> Quantiles (5 min)</h3>
<p>More general than a median is a <em>quantile</em>. The definition of a <span class="math inline">\(p\)</span>-quantile <span class="math inline">\(Q(p)\)</span> is the outcome that has a <span class="math inline">\(1-p\)</span> probability of exceedance, or equivalently, for which thereâs a probability <span class="math inline">\(p\)</span> of getting a smaller outcome. So, its distribution-based definition satisfies <span class="math display">\[P(X \leq Q(p)) = p.\]</span> The median is a special case, and is the 0.5-quantile.</p>
<p>An empirically-based definition of the <span class="math inline">\(p\)</span>-quantile is the <span class="math inline">\(np\)</span>âth largest (rounded up) observation in a sample of size <span class="math inline">\(n\)</span>.</p>
<p>Some quantiles have a special name:</p>
<ul>
<li>The 0.25-, 0.5-, and 0.75-quantiles are called <em>quartiles</em>.
<ul>
<li>Sometimes named the first, second, and third quartiles, respectively.</li>
</ul></li>
<li>The 0.01-, 0.02, â¦, and 0.99-quantiles are called <em>percentiles</em>.
<ul>
<li>Sometimes the <span class="math inline">\(p\)</span>-quantile will be called the <span class="math inline">\(100p\)</span>âth percentile; for example, the 40th percentile is the 0.4-quantile.</li>
</ul></li>
<li>Less commonly, there are even <em>deciles</em>, as the 0.1, 0.2, â¦, and 0.9-quantiles.</li>
</ul>
<p>For example, the 0.25-quantile of octane purity at Low Purity Octane is 0.5, since the area to the left of 0.5 is 0.25:</p>
<p><img src="lecture05_files/figure-html/unnamed-chunk-8-1.png" width="384" style="display: block; margin: auto;" /></p>
</div>
<div id="prediction-intervals-5-min" class="section level3">
<h3><span class="header-section-number">5.5.4</span> Prediction Intervals (5 min)</h3>
<p>Itâs often useful to communicate an interval for which a random outcome will fall in with a pre-specified probability <span class="math inline">\(p\)</span>. Such an interval is called a <span class="math inline">\(p \times 100\%\)</span> <strong>Prediction Interval</strong>.</p>
<p>Usually, we set this up in such a way that thereâs a <span class="math inline">\(p/2\)</span> chance of exceeding the interval, and <span class="math inline">\(p/2\)</span> chance of undershooting the interval. You can calculate the lower limit of this interval as the <span class="math inline">\((1 - p)/2\)</span>-Quantile, and the upper limit as the <span class="math inline">\(1 - (1 - p)/2\)</span>-Quantile.</p>
<p><strong>Example</strong>: a 90% prediction interval for the purity of gasoline at âLow Purity Octaneâ is [0.2236, 0.9746], composed of the 0.05- and 0.95-quantiles.</p>
<p><img src="lecture05_files/figure-html/unnamed-chunk-9-1.png" width="384" style="display: block; margin: auto;" /></p>
</div>
<div id="skewness-5-min" class="section level3">
<h3><span class="header-section-number">5.5.5</span> Skewness (5 min)</h3>
<p>Skewness measures how âlopsidedâ a distribution is, as well as the direction of the skew.</p>
<ul>
<li>If the density is symmetric about a point, then the skewness is 0.</li>
<li>If the density is more âspread-outâ towards the right / positive values, then the distribution is said to be <em>right-skewed</em> (positive skewness).</li>
<li>If the density is more âspread-outâ towards the left / negative values, then the distribution is said to be <em>left-skewed</em> (negative skewness).</li>
</ul>
<p><img src="lecture05_files/figure-html/unnamed-chunk-10-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>It turns out that for symmetric distributions, the <em>mean and median</em> are equivalent. But otherwise, the mean tends to be further into the skewed part of the distribution. Using the monthly expense example, the mean monthly expense is $3377.87, which is bigger than the median monthly expense of $2980.96.</p>
<p><img src="lecture05_files/figure-html/unnamed-chunk-11-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>Formally, skewness can be defined as <span class="math display">\[\text{Skewness} = E \left( \left( \frac{X - \mu_X}{\sigma_X} \right) ^ 3 \right),\]</span> where <span class="math inline">\(\mu_X = E(X)\)</span> and <span class="math inline">\(\sigma_X = \text{SD}(X)\)</span>.</p>
<p>For example, the octane purity distribution is left-skewed, and has a skewness of <span class="math display">\[\int_0^1 2  x  \left(\sqrt{18} (x - 2/3) \right) ^ 3 \text{d}x \doteq -0.5657.\]</span></p>
</div>
<div id="examples" class="section level3">
<h3><span class="header-section-number">5.5.6</span> Examples</h3>
<p>For the following situations, which quantity is most appropriate, and why?</p>
<ul>
<li>You want to know your monthly expenses in the long run (say, for forecasting net gains after many months). How do you communicate total expense?</li>
<li>You want to ensure you put enough money aside on a given month to ensure youâll have enough money to pay your bills. How much should you put aside?</li>
<li>How should you communicate the cost of a typical house in North Vancouver?</li>
</ul>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="joint-probability-part-i.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="joint-probability-part-ii.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.ubc.ca/MDS-2019-20/DSCI_551_stat-prob-dsci_students/edit/master/lecture05.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
